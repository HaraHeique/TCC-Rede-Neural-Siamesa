{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCC-rede-neural-siamesa.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1CwimdvnCS9tT1Dt9qwQkrX5iLFeTzWTr",
      "authorship_tag": "ABX9TyOLx0M4X6QB76ogoCfXCiux",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaraHeique/TCC-rede-neural-siamesa/blob/master/TCC_rede_neural_siamesa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC_lB9Jl-rUC"
      },
      "source": [
        "**Conect to google drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J87p4iR5ff2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb69dc67-44e1-4c26-8dbd-f97f2a01a6b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjPhx03R_Y5j"
      },
      "source": [
        "**Check the neural network source code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnVbVeg7qChu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687f15dd-1bd2-471b-beb9-0b60193564ed"
      },
      "source": [
        "%cd \"/content/gdrive/My Drive/BSI/TCC/Códigos/TCC-rede-siamesa-google-colab\"\n",
        "%ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/BSI/TCC/Códigos/TCC-rede-siamesa-google-colab\n",
            "cli_input.py                           prediction.py\n",
            "cli_output.py                          \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n",
            "data_structuring.py                    requirements.txt\n",
            "GoogleNews-vectors-negative300.bin.gz  SiameseLSTM.h5\n",
            "helper.py                              Stage.py\n",
            "history-graph-70-30-100-5.png          test100.csv\n",
            "main.py                                test30.csv\n",
            "ManhattanDistance.py                   training-36000-sentences.csv\n",
            "prediction-180-sentences.csv           training-default.csv\n",
            "prediction-600-sentences.csv           training.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWTp9uKYMmvg"
      },
      "source": [
        "**Install dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ag_ETZf7Mn0z",
        "outputId": "4fd855ee-8f2d-44d9-e4f2-e1770a735082"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.18.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 1.4MB/s \n",
            "\u001b[?25hCollecting pandas==1.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/b9/9ad570258ce4fe504bd23002154f9e6f09bf7110359d271e4ba1664f7281/pandas-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 20.6MB/s \n",
            "\u001b[?25hCollecting tensorflow==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 31kB/s \n",
            "\u001b[?25hCollecting tensorflow-addons==0.11.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/f8/d6fca180c123f2851035c4493690662ebdad0849a9059d56035434bff5c9/tensorflow_addons-0.11.2-cp36-cp36m-manylinux2010_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 32kB/s \n",
            "\u001b[?25hCollecting gensim==3.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 1.4MB/s \n",
            "\u001b[?25hCollecting nltk==3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 50.6MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/ae/81b1c98ae97350711adb021ee12ea678b37f608ec2faa35c3a7db11795fa/matplotlib-3.3.0-1-cp36-cp36m-manylinux1_x86_64.whl (11.5MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5MB 20.4MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/3a/eb8d7bbe28f4787d140bb9df685b7d5bf6115c0e2a969def4027144e98b6/scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 28.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.2->-r requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.2->-r requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 57.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (1.12.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (2.10.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r requirements.txt (line 3)) (1.4.1)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons==0.11.2->-r requirements.txt (line 4)) (2.7.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim==3.8.3->-r requirements.txt (line 5)) (4.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk==3.5->-r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk==3.5->-r requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk==3.5->-r requirements.txt (line 6)) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk==3.5->-r requirements.txt (line 6)) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.0->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.0->-r requirements.txt (line 7)) (7.0.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.0->-r requirements.txt (line 7)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.3.0->-r requirements.txt (line 7)) (0.10.0)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (3.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r requirements.txt (line 3)) (0.4.8)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434675 sha256=2d7025fa2b3c945bb222b34b15b3a362e7e00564ec922420bd0e630f5f69366b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "Successfully built nltk\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 1.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, pandas, tensorflow-estimator, tensorboard, tensorflow, tensorflow-addons, gensim, nltk, matplotlib, threadpoolctl, scikit-learn\n",
            "  Found existing installation: numpy 1.19.4\n",
            "    Uninstalling numpy-1.19.4:\n",
            "      Successfully uninstalled numpy-1.19.4\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "  Found existing installation: tensorflow-addons 0.8.3\n",
            "    Uninstalling tensorflow-addons-0.8.3:\n",
            "      Successfully uninstalled tensorflow-addons-0.8.3\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed gensim-3.8.3 matplotlib-3.3.0 nltk-3.5 numpy-1.18.1 pandas-1.0.2 scikit-learn-0.23.1 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-addons-0.11.2 tensorflow-estimator-2.2.0 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccl5eCIyNEjw"
      },
      "source": [
        "**Check dependecies installed**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76VDdtxlNcrk",
        "outputId": "00d261a7-de7c-469e-860d-94da5ae0cebe"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Package                       Version        \n",
            "----------------------------- ---------------\n",
            "absl-py                       0.10.0         \n",
            "alabaster                     0.7.12         \n",
            "albumentations                0.1.12         \n",
            "altair                        4.1.0          \n",
            "argon2-cffi                   20.1.0         \n",
            "asgiref                       3.3.1          \n",
            "astor                         0.8.1          \n",
            "astropy                       4.1            \n",
            "astunparse                    1.6.3          \n",
            "async-generator               1.10           \n",
            "atari-py                      0.2.6          \n",
            "atomicwrites                  1.4.0          \n",
            "attrs                         20.3.0         \n",
            "audioread                     2.1.9          \n",
            "autograd                      1.3            \n",
            "Babel                         2.9.0          \n",
            "backcall                      0.2.0          \n",
            "beautifulsoup4                4.6.3          \n",
            "bleach                        3.2.1          \n",
            "blis                          0.4.1          \n",
            "bokeh                         2.1.1          \n",
            "Bottleneck                    1.3.2          \n",
            "branca                        0.4.1          \n",
            "bs4                           0.0.1          \n",
            "CacheControl                  0.12.6         \n",
            "cachetools                    4.2.0          \n",
            "catalogue                     1.0.0          \n",
            "certifi                       2020.12.5      \n",
            "cffi                          1.14.4         \n",
            "chainer                       7.4.0          \n",
            "chardet                       3.0.4          \n",
            "click                         7.1.2          \n",
            "cloudpickle                   1.3.0          \n",
            "cmake                         3.12.0         \n",
            "cmdstanpy                     0.9.5          \n",
            "colorlover                    0.3.0          \n",
            "community                     1.0.0b1        \n",
            "contextlib2                   0.5.5          \n",
            "convertdate                   2.2.0          \n",
            "coverage                      3.7.1          \n",
            "coveralls                     0.5            \n",
            "crcmod                        1.7            \n",
            "cufflinks                     0.17.3         \n",
            "cupy-cuda101                  7.4.0          \n",
            "cvxopt                        1.2.5          \n",
            "cvxpy                         1.0.31         \n",
            "cycler                        0.10.0         \n",
            "cymem                         2.0.5          \n",
            "Cython                        0.29.21        \n",
            "daft                          0.0.4          \n",
            "dask                          2.12.0         \n",
            "dataclasses                   0.8            \n",
            "datascience                   0.10.6         \n",
            "debugpy                       1.0.0          \n",
            "decorator                     4.4.2          \n",
            "defusedxml                    0.6.0          \n",
            "descartes                     1.1.0          \n",
            "dill                          0.3.3          \n",
            "distributed                   1.25.3         \n",
            "Django                        3.1.4          \n",
            "dlib                          19.18.0        \n",
            "dm-tree                       0.1.5          \n",
            "docopt                        0.6.2          \n",
            "docutils                      0.16           \n",
            "dopamine-rl                   1.0.5          \n",
            "earthengine-api               0.1.238        \n",
            "easydict                      1.9            \n",
            "ecos                          2.0.7.post1    \n",
            "editdistance                  0.5.3          \n",
            "en-core-web-sm                2.2.5          \n",
            "entrypoints                   0.3            \n",
            "ephem                         3.7.7.1        \n",
            "et-xmlfile                    1.0.1          \n",
            "fa2                           0.3.5          \n",
            "fancyimpute                   0.4.3          \n",
            "fastai                        1.0.61         \n",
            "fastdtw                       0.3.4          \n",
            "fastprogress                  1.0.0          \n",
            "fastrlock                     0.5            \n",
            "fbprophet                     0.7.1          \n",
            "feather-format                0.4.1          \n",
            "filelock                      3.0.12         \n",
            "firebase-admin                4.4.0          \n",
            "fix-yahoo-finance             0.0.22         \n",
            "Flask                         1.1.2          \n",
            "flatbuffers                   1.12           \n",
            "folium                        0.8.3          \n",
            "future                        0.16.0         \n",
            "gast                          0.3.3          \n",
            "GDAL                          2.2.2          \n",
            "gdown                         3.6.4          \n",
            "gensim                        3.8.3          \n",
            "geographiclib                 1.50           \n",
            "geopy                         1.17.0         \n",
            "gin-config                    0.4.0          \n",
            "glob2                         0.7            \n",
            "google                        2.0.3          \n",
            "google-api-core               1.16.0         \n",
            "google-api-python-client      1.7.12         \n",
            "google-auth                   1.17.2         \n",
            "google-auth-httplib2          0.0.4          \n",
            "google-auth-oauthlib          0.4.2          \n",
            "google-cloud-bigquery         1.21.0         \n",
            "google-cloud-bigquery-storage 1.1.0          \n",
            "google-cloud-core             1.0.3          \n",
            "google-cloud-datastore        1.8.0          \n",
            "google-cloud-firestore        1.7.0          \n",
            "google-cloud-language         1.2.0          \n",
            "google-cloud-storage          1.18.1         \n",
            "google-cloud-translate        1.5.0          \n",
            "google-colab                  1.0.0          \n",
            "google-pasta                  0.2.0          \n",
            "google-resumable-media        0.4.1          \n",
            "googleapis-common-protos      1.52.0         \n",
            "googledrivedownloader         0.4            \n",
            "graphviz                      0.10.1         \n",
            "grpcio                        1.32.0         \n",
            "gspread                       3.0.1          \n",
            "gspread-dataframe             3.0.8          \n",
            "gym                           0.17.3         \n",
            "h5py                          2.10.0         \n",
            "HeapDict                      1.0.1          \n",
            "holidays                      0.10.4         \n",
            "holoviews                     1.13.5         \n",
            "html5lib                      1.0.1          \n",
            "httpimport                    0.5.18         \n",
            "httplib2                      0.17.4         \n",
            "httplib2shim                  0.0.3          \n",
            "humanize                      0.5.1          \n",
            "hyperopt                      0.1.2          \n",
            "ideep4py                      2.0.0.post3    \n",
            "idna                          2.10           \n",
            "image                         1.5.33         \n",
            "imageio                       2.4.1          \n",
            "imagesize                     1.2.0          \n",
            "imbalanced-learn              0.4.3          \n",
            "imblearn                      0.0            \n",
            "imgaug                        0.2.9          \n",
            "importlib-metadata            3.3.0          \n",
            "importlib-resources           3.3.0          \n",
            "imutils                       0.5.3          \n",
            "inflect                       2.1.0          \n",
            "iniconfig                     1.1.1          \n",
            "intel-openmp                  2021.1.1       \n",
            "intervaltree                  2.1.0          \n",
            "ipykernel                     4.10.1         \n",
            "ipython                       5.5.0          \n",
            "ipython-genutils              0.2.0          \n",
            "ipython-sql                   0.3.9          \n",
            "ipywidgets                    7.5.1          \n",
            "itsdangerous                  1.1.0          \n",
            "jax                           0.2.7          \n",
            "jaxlib                        0.1.57+cuda101 \n",
            "jdcal                         1.4.1          \n",
            "jedi                          0.17.2         \n",
            "jieba                         0.42.1         \n",
            "Jinja2                        2.11.2         \n",
            "joblib                        1.0.0          \n",
            "jpeg4py                       0.1.4          \n",
            "jsonschema                    2.6.0          \n",
            "jupyter                       1.0.0          \n",
            "jupyter-client                5.3.5          \n",
            "jupyter-console               5.2.0          \n",
            "jupyter-core                  4.7.0          \n",
            "jupyterlab-pygments           0.1.2          \n",
            "kaggle                        1.5.10         \n",
            "kapre                         0.1.3.1        \n",
            "Keras                         2.4.3          \n",
            "Keras-Preprocessing           1.1.2          \n",
            "keras-vis                     0.4.1          \n",
            "kiwisolver                    1.3.1          \n",
            "knnimpute                     0.1.0          \n",
            "korean-lunar-calendar         0.2.1          \n",
            "librosa                       0.6.3          \n",
            "lightgbm                      2.2.3          \n",
            "llvmlite                      0.31.0         \n",
            "lmdb                          0.99           \n",
            "lucid                         0.3.8          \n",
            "LunarCalendar                 0.0.9          \n",
            "lxml                          4.2.6          \n",
            "Markdown                      3.3.3          \n",
            "MarkupSafe                    1.1.1          \n",
            "matplotlib                    3.3.0          \n",
            "matplotlib-venn               0.11.6         \n",
            "missingno                     0.4.2          \n",
            "mistune                       0.8.4          \n",
            "mizani                        0.6.0          \n",
            "mkl                           2019.0         \n",
            "mlxtend                       0.14.0         \n",
            "more-itertools                8.6.0          \n",
            "moviepy                       0.2.3.5        \n",
            "mpmath                        1.1.0          \n",
            "msgpack                       1.0.1          \n",
            "multiprocess                  0.70.11.1      \n",
            "multitasking                  0.0.9          \n",
            "murmurhash                    1.0.5          \n",
            "music21                       5.5.0          \n",
            "natsort                       5.5.0          \n",
            "nbclient                      0.5.1          \n",
            "nbconvert                     5.6.1          \n",
            "nbformat                      5.0.8          \n",
            "nest-asyncio                  1.4.3          \n",
            "networkx                      2.5            \n",
            "nibabel                       3.0.2          \n",
            "nltk                          3.5            \n",
            "notebook                      5.3.1          \n",
            "np-utils                      0.5.12.1       \n",
            "numba                         0.48.0         \n",
            "numexpr                       2.7.1          \n",
            "numpy                         1.18.1         \n",
            "nvidia-ml-py3                 7.352.0        \n",
            "oauth2client                  4.1.3          \n",
            "oauthlib                      3.1.0          \n",
            "okgrade                       0.4.3          \n",
            "opencv-contrib-python         4.1.2.30       \n",
            "opencv-python                 4.1.2.30       \n",
            "openpyxl                      2.5.9          \n",
            "opt-einsum                    3.3.0          \n",
            "osqp                          0.6.1          \n",
            "packaging                     20.8           \n",
            "palettable                    3.3.0          \n",
            "pandas                        1.0.2          \n",
            "pandas-datareader             0.9.0          \n",
            "pandas-gbq                    0.13.3         \n",
            "pandas-profiling              1.4.1          \n",
            "pandocfilters                 1.4.3          \n",
            "panel                         0.9.7          \n",
            "param                         1.10.0         \n",
            "parso                         0.7.1          \n",
            "pathlib                       1.0.1          \n",
            "patsy                         0.5.1          \n",
            "pexpect                       4.8.0          \n",
            "pickleshare                   0.7.5          \n",
            "Pillow                        7.0.0          \n",
            "pip                           19.3.1         \n",
            "pip-tools                     4.5.1          \n",
            "plac                          1.1.3          \n",
            "plotly                        4.4.1          \n",
            "plotnine                      0.6.0          \n",
            "pluggy                        0.7.1          \n",
            "portpicker                    1.3.1          \n",
            "prefetch-generator            1.0.1          \n",
            "preshed                       3.0.5          \n",
            "prettytable                   2.0.0          \n",
            "progressbar2                  3.38.0         \n",
            "prometheus-client             0.9.0          \n",
            "promise                       2.3            \n",
            "prompt-toolkit                1.0.18         \n",
            "protobuf                      3.12.4         \n",
            "psutil                        5.4.8          \n",
            "psycopg2                      2.7.6.1        \n",
            "ptyprocess                    0.6.0          \n",
            "py                            1.10.0         \n",
            "pyarrow                       0.14.1         \n",
            "pyasn1                        0.4.8          \n",
            "pyasn1-modules                0.2.8          \n",
            "pycocotools                   2.0.2          \n",
            "pycparser                     2.20           \n",
            "pyct                          0.4.8          \n",
            "pydata-google-auth            1.1.0          \n",
            "pydot                         1.3.0          \n",
            "pydot-ng                      2.0.0          \n",
            "pydotplus                     2.0.2          \n",
            "PyDrive                       1.3.1          \n",
            "pyemd                         0.5.1          \n",
            "pyglet                        1.5.0          \n",
            "Pygments                      2.6.1          \n",
            "pygobject                     3.26.1         \n",
            "pymc3                         3.7            \n",
            "PyMeeus                       0.3.7          \n",
            "pymongo                       3.11.2         \n",
            "pymystem3                     0.2.0          \n",
            "PyOpenGL                      3.1.5          \n",
            "pyparsing                     2.4.7          \n",
            "pyrsistent                    0.17.3         \n",
            "pysndfile                     1.3.8          \n",
            "PySocks                       1.7.1          \n",
            "pystan                        2.19.1.1       \n",
            "pytest                        3.6.4          \n",
            "python-apt                    1.6.5+ubuntu0.3\n",
            "python-chess                  0.23.11        \n",
            "python-dateutil               2.8.1          \n",
            "python-louvain                0.14           \n",
            "python-slugify                4.0.1          \n",
            "python-utils                  2.4.0          \n",
            "pytz                          2018.9         \n",
            "pyviz-comms                   0.7.6          \n",
            "PyWavelets                    1.1.1          \n",
            "PyYAML                        3.13           \n",
            "pyzmq                         20.0.0         \n",
            "qtconsole                     5.0.1          \n",
            "QtPy                          1.9.0          \n",
            "regex                         2019.12.20     \n",
            "requests                      2.23.0         \n",
            "requests-oauthlib             1.3.0          \n",
            "resampy                       0.2.2          \n",
            "retrying                      1.3.3          \n",
            "rpy2                          3.2.7          \n",
            "rsa                           4.6            \n",
            "scikit-image                  0.16.2         \n",
            "scikit-learn                  0.23.1         \n",
            "scipy                         1.4.1          \n",
            "screen-resolution-extra       0.0.0          \n",
            "scs                           2.1.2          \n",
            "seaborn                       0.11.0         \n",
            "Send2Trash                    1.5.0          \n",
            "setuptools                    50.3.2         \n",
            "setuptools-git                1.2            \n",
            "Shapely                       1.7.1          \n",
            "simplegeneric                 0.8.1          \n",
            "six                           1.15.0         \n",
            "sklearn                       0.0            \n",
            "sklearn-pandas                1.8.0          \n",
            "smart-open                    4.0.1          \n",
            "snowballstemmer               2.0.0          \n",
            "sortedcontainers              2.3.0          \n",
            "spacy                         2.2.4          \n",
            "Sphinx                        1.8.5          \n",
            "sphinxcontrib-serializinghtml 1.1.4          \n",
            "sphinxcontrib-websupport      1.2.4          \n",
            "SQLAlchemy                    1.3.20         \n",
            "sqlparse                      0.4.1          \n",
            "srsly                         1.0.5          \n",
            "statsmodels                   0.10.2         \n",
            "sympy                         1.1.1          \n",
            "tables                        3.4.4          \n",
            "tabulate                      0.8.7          \n",
            "tblib                         1.7.0          \n",
            "tensorboard                   2.2.2          \n",
            "tensorboard-plugin-wit        1.7.0          \n",
            "tensorboardcolab              0.0.22         \n",
            "tensorflow                    2.2.0          \n",
            "tensorflow-addons             0.11.2         \n",
            "tensorflow-datasets           4.0.1          \n",
            "tensorflow-estimator          2.2.0          \n",
            "tensorflow-gcs-config         2.4.0          \n",
            "tensorflow-hub                0.10.0         \n",
            "tensorflow-metadata           0.26.0         \n",
            "tensorflow-privacy            0.2.2          \n",
            "tensorflow-probability        0.11.0         \n",
            "termcolor                     1.1.0          \n",
            "terminado                     0.9.1          \n",
            "testpath                      0.4.4          \n",
            "text-unidecode                1.3            \n",
            "textblob                      0.15.3         \n",
            "textgenrnn                    1.4.1          \n",
            "Theano                        1.0.5          \n",
            "thinc                         7.4.0          \n",
            "threadpoolctl                 2.1.0          \n",
            "tifffile                      2020.9.3       \n",
            "toml                          0.10.2         \n",
            "toolz                         0.11.1         \n",
            "torch                         1.7.0+cu101    \n",
            "torchsummary                  1.5.1          \n",
            "torchtext                     0.3.1          \n",
            "torchvision                   0.8.1+cu101    \n",
            "tornado                       5.1.1          \n",
            "tqdm                          4.41.1         \n",
            "traitlets                     4.3.3          \n",
            "tweepy                        3.6.0          \n",
            "typeguard                     2.7.1          \n",
            "typing-extensions             3.7.4.3        \n",
            "tzlocal                       1.5.1          \n",
            "umap-learn                    0.4.6          \n",
            "uritemplate                   3.0.1          \n",
            "urllib3                       1.24.3         \n",
            "vega-datasets                 0.9.0          \n",
            "wasabi                        0.8.0          \n",
            "wcwidth                       0.2.5          \n",
            "webencodings                  0.5.1          \n",
            "Werkzeug                      1.0.1          \n",
            "wheel                         0.36.2         \n",
            "widgetsnbextension            3.5.1          \n",
            "wordcloud                     1.5.0          \n",
            "wrapt                         1.12.1         \n",
            "xarray                        0.15.1         \n",
            "xgboost                       0.90           \n",
            "xkit                          0.0.0          \n",
            "xlrd                          1.1.0          \n",
            "xlwt                          1.3.0          \n",
            "yellowbrick                   0.9.1          \n",
            "zict                          2.0.0          \n",
            "zipp                          3.4.0          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7PasuYKALP1"
      },
      "source": [
        "**Run code from main.py**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMwbmflBtlbv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10dca8a3-23be-4bcb-8f8a-f8fa532de189"
      },
      "source": [
        "!python3 main.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What would you like to do?\n",
            " 0 - Leave\n",
            " 1 - Data Structure\n",
            " 2 - Train\n",
            " 3 - Predict\n",
            "2\n",
            "\u001b[H\u001b[2JEnter the name of the training file located inside the /data/training: training-36000-sentencescsv\n",
            "The filename training-36000-sentencescsv does not exist. Try again\n",
            "Enter the name of the training file located inside the /data/training: training-36000-sentences.csv\n",
            "Enter the percent of validation between 0% and 30%: 30\n",
            "Enter the number of epochs to train: 100\n",
            "Enter the number of max sequence length to train: 5\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Loading word2vec model (it may takes around 2-3 minutes)...\n",
            "tcmalloc: large alloc 3600007168 bytes == 0x8458000 @  0x7efee68d0001 0x7efee2cd9765 0x7efee2d3ddc0 0x7efee2d3fc5f 0x7efee2dd6238 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "word2vec loaded\n",
            "1,000 sentences embedded.\n",
            "2,000 sentences embedded.\n",
            "3,000 sentences embedded.\n",
            "4,000 sentences embedded.\n",
            "5,000 sentences embedded.\n",
            "6,000 sentences embedded.\n",
            "7,000 sentences embedded.\n",
            "8,000 sentences embedded.\n",
            "9,000 sentences embedded.\n",
            "10,000 sentences embedded.\n",
            "11,000 sentences embedded.\n",
            "12,000 sentences embedded.\n",
            "13,000 sentences embedded.\n",
            "14,000 sentences embedded.\n",
            "15,000 sentences embedded.\n",
            "16,000 sentences embedded.\n",
            "17,000 sentences embedded.\n",
            "2020-12-20 19:45:40.047544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-20 19:45:40.115733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 19:45:40.116328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-12-20 19:45:40.123473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-20 19:45:40.342651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-12-20 19:45:40.453090: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-12-20 19:45:40.495975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-12-20 19:45:40.742274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-12-20 19:45:40.791953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-12-20 19:45:41.284208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-20 19:45:41.284473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 19:45:41.285133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 19:45:41.285675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-12-20 19:45:41.290505: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-12-20 19:45:41.334837: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2199995000 Hz\n",
            "2020-12-20 19:45:41.335178: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2742bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-20 19:45:41.335212: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-12-20 19:45:41.484011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 19:45:41.484707: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2742d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-20 19:45:41.484736: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-12-20 19:45:41.488084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 19:45:41.488600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-12-20 19:45:41.488705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-20 19:45:41.488743: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-12-20 19:45:41.488771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-12-20 19:45:41.488795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-12-20 19:45:41.488818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-12-20 19:45:41.488840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-12-20 19:45:41.488863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-20 19:45:41.488949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 19:45:41.489567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 19:45:41.490122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
            "2020-12-20 19:45:41.495667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-20 19:45:41.497050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-12-20 19:45:41.497079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
            "2020-12-20 19:45:41.497091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
            "2020-12-20 19:45:41.502276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 19:45:41.502946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-20 19:45:41.505931: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-12-20 19:45:41.505988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14071 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 50)           4350600     input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "manhattan_distance (ManhattanDi (None, 1)            0           sequential[1][0]                 \n",
            "                                                                 sequential[2][0]                 \n",
            "==================================================================================================\n",
            "Total params: 4,350,600\n",
            "Trainable params: 70,200\n",
            "Non-trainable params: 4,280,400\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "2020-12-20 19:45:54.379292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "99/99 [==============================] - 1s 13ms/step - loss: 1.1458 - accuracy: 0.3579 - val_loss: 0.8495 - val_accuracy: 0.3756\n",
            "Epoch 2/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.7776 - accuracy: 0.3848 - val_loss: 0.7287 - val_accuracy: 0.3787\n",
            "Epoch 3/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6976 - accuracy: 0.3879 - val_loss: 0.6858 - val_accuracy: 0.3796\n",
            "Epoch 4/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6614 - accuracy: 0.3924 - val_loss: 0.6638 - val_accuracy: 0.3831\n",
            "Epoch 5/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6403 - accuracy: 0.4002 - val_loss: 0.6496 - val_accuracy: 0.3937\n",
            "Epoch 6/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6257 - accuracy: 0.4090 - val_loss: 0.6387 - val_accuracy: 0.4015\n",
            "Epoch 7/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6149 - accuracy: 0.4157 - val_loss: 0.6299 - val_accuracy: 0.4067\n",
            "Epoch 8/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6056 - accuracy: 0.4223 - val_loss: 0.6227 - val_accuracy: 0.4131\n",
            "Epoch 9/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5979 - accuracy: 0.4269 - val_loss: 0.6162 - val_accuracy: 0.4172\n",
            "Epoch 10/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5915 - accuracy: 0.4319 - val_loss: 0.6108 - val_accuracy: 0.4215\n",
            "Epoch 11/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5862 - accuracy: 0.4352 - val_loss: 0.6066 - val_accuracy: 0.4228\n",
            "Epoch 12/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5812 - accuracy: 0.4390 - val_loss: 0.6018 - val_accuracy: 0.4250\n",
            "Epoch 13/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5761 - accuracy: 0.4423 - val_loss: 0.5981 - val_accuracy: 0.4311\n",
            "Epoch 14/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5713 - accuracy: 0.4492 - val_loss: 0.5927 - val_accuracy: 0.4354\n",
            "Epoch 15/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5646 - accuracy: 0.4528 - val_loss: 0.5887 - val_accuracy: 0.4483\n",
            "Epoch 16/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5589 - accuracy: 0.4603 - val_loss: 0.5830 - val_accuracy: 0.4513\n",
            "Epoch 17/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5529 - accuracy: 0.4667 - val_loss: 0.5791 - val_accuracy: 0.4470\n",
            "Epoch 18/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5476 - accuracy: 0.4749 - val_loss: 0.5749 - val_accuracy: 0.4598\n",
            "Epoch 19/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5428 - accuracy: 0.4835 - val_loss: 0.5722 - val_accuracy: 0.4720\n",
            "Epoch 20/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5383 - accuracy: 0.4883 - val_loss: 0.5668 - val_accuracy: 0.4757\n",
            "Epoch 21/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5338 - accuracy: 0.4910 - val_loss: 0.5645 - val_accuracy: 0.4791\n",
            "Epoch 22/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5303 - accuracy: 0.4938 - val_loss: 0.5625 - val_accuracy: 0.4828\n",
            "Epoch 23/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5273 - accuracy: 0.4967 - val_loss: 0.5591 - val_accuracy: 0.4826\n",
            "Epoch 24/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5243 - accuracy: 0.4987 - val_loss: 0.5579 - val_accuracy: 0.4867\n",
            "Epoch 25/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5223 - accuracy: 0.5006 - val_loss: 0.5561 - val_accuracy: 0.4885\n",
            "Epoch 26/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5197 - accuracy: 0.5026 - val_loss: 0.5559 - val_accuracy: 0.4906\n",
            "Epoch 27/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5185 - accuracy: 0.5040 - val_loss: 0.5530 - val_accuracy: 0.4906\n",
            "Epoch 28/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5163 - accuracy: 0.5058 - val_loss: 0.5522 - val_accuracy: 0.4917\n",
            "Epoch 29/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5146 - accuracy: 0.5066 - val_loss: 0.5516 - val_accuracy: 0.4941\n",
            "Epoch 30/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5135 - accuracy: 0.5074 - val_loss: 0.5504 - val_accuracy: 0.4950\n",
            "Epoch 31/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5125 - accuracy: 0.5075 - val_loss: 0.5497 - val_accuracy: 0.4959\n",
            "Epoch 32/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5107 - accuracy: 0.5093 - val_loss: 0.5494 - val_accuracy: 0.4972\n",
            "Epoch 33/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5100 - accuracy: 0.5102 - val_loss: 0.5505 - val_accuracy: 0.4998\n",
            "Epoch 34/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5086 - accuracy: 0.5112 - val_loss: 0.5480 - val_accuracy: 0.4994\n",
            "Epoch 35/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5061 - accuracy: 0.5129 - val_loss: 0.5474 - val_accuracy: 0.5006\n",
            "Epoch 36/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5048 - accuracy: 0.5133 - val_loss: 0.5467 - val_accuracy: 0.5017\n",
            "Epoch 37/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5033 - accuracy: 0.5156 - val_loss: 0.5461 - val_accuracy: 0.5013\n",
            "Epoch 38/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5024 - accuracy: 0.5160 - val_loss: 0.5453 - val_accuracy: 0.5028\n",
            "Epoch 39/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5012 - accuracy: 0.5172 - val_loss: 0.5450 - val_accuracy: 0.5043\n",
            "Epoch 40/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5000 - accuracy: 0.5175 - val_loss: 0.5470 - val_accuracy: 0.5041\n",
            "Epoch 41/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4995 - accuracy: 0.5198 - val_loss: 0.5445 - val_accuracy: 0.5039\n",
            "Epoch 42/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4983 - accuracy: 0.5212 - val_loss: 0.5440 - val_accuracy: 0.5056\n",
            "Epoch 43/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4981 - accuracy: 0.5214 - val_loss: 0.5462 - val_accuracy: 0.5015\n",
            "Epoch 44/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4970 - accuracy: 0.5228 - val_loss: 0.5447 - val_accuracy: 0.5050\n",
            "Epoch 45/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4951 - accuracy: 0.5242 - val_loss: 0.5439 - val_accuracy: 0.5070\n",
            "Epoch 46/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4934 - accuracy: 0.5244 - val_loss: 0.5440 - val_accuracy: 0.5059\n",
            "Epoch 47/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4934 - accuracy: 0.5251 - val_loss: 0.5440 - val_accuracy: 0.5067\n",
            "Epoch 48/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4922 - accuracy: 0.5253 - val_loss: 0.5442 - val_accuracy: 0.5080\n",
            "Epoch 49/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4961 - accuracy: 0.5259 - val_loss: 0.5483 - val_accuracy: 0.5078\n",
            "Epoch 50/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4941 - accuracy: 0.5272 - val_loss: 0.5447 - val_accuracy: 0.5087\n",
            "Epoch 51/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4926 - accuracy: 0.5279 - val_loss: 0.5434 - val_accuracy: 0.5089\n",
            "Epoch 52/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4920 - accuracy: 0.5286 - val_loss: 0.5446 - val_accuracy: 0.5100\n",
            "Epoch 53/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4908 - accuracy: 0.5296 - val_loss: 0.5477 - val_accuracy: 0.5106\n",
            "Epoch 54/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4931 - accuracy: 0.5285 - val_loss: 0.5469 - val_accuracy: 0.5109\n",
            "Epoch 55/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4897 - accuracy: 0.5313 - val_loss: 0.5450 - val_accuracy: 0.5117\n",
            "Epoch 56/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4878 - accuracy: 0.5326 - val_loss: 0.5454 - val_accuracy: 0.5126\n",
            "Epoch 57/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4863 - accuracy: 0.5345 - val_loss: 0.5442 - val_accuracy: 0.5130\n",
            "Epoch 58/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4854 - accuracy: 0.5351 - val_loss: 0.5439 - val_accuracy: 0.5131\n",
            "Epoch 59/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4842 - accuracy: 0.5359 - val_loss: 0.5433 - val_accuracy: 0.5144\n",
            "Epoch 60/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4833 - accuracy: 0.5363 - val_loss: 0.5434 - val_accuracy: 0.5150\n",
            "Epoch 61/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4826 - accuracy: 0.5370 - val_loss: 0.5429 - val_accuracy: 0.5157\n",
            "Epoch 62/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4816 - accuracy: 0.5387 - val_loss: 0.5423 - val_accuracy: 0.5156\n",
            "Epoch 63/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4804 - accuracy: 0.5390 - val_loss: 0.5425 - val_accuracy: 0.5170\n",
            "Epoch 64/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4794 - accuracy: 0.5402 - val_loss: 0.5420 - val_accuracy: 0.5161\n",
            "Epoch 65/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4784 - accuracy: 0.5405 - val_loss: 0.5422 - val_accuracy: 0.5183\n",
            "Epoch 66/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4777 - accuracy: 0.5405 - val_loss: 0.5425 - val_accuracy: 0.5172\n",
            "Epoch 67/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4768 - accuracy: 0.5426 - val_loss: 0.5416 - val_accuracy: 0.5202\n",
            "Epoch 68/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4763 - accuracy: 0.5436 - val_loss: 0.5425 - val_accuracy: 0.5198\n",
            "Epoch 69/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4753 - accuracy: 0.5436 - val_loss: 0.5412 - val_accuracy: 0.5196\n",
            "Epoch 70/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4748 - accuracy: 0.5440 - val_loss: 0.5411 - val_accuracy: 0.5207\n",
            "Epoch 71/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4740 - accuracy: 0.5452 - val_loss: 0.5410 - val_accuracy: 0.5209\n",
            "Epoch 72/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4735 - accuracy: 0.5458 - val_loss: 0.5415 - val_accuracy: 0.5217\n",
            "Epoch 73/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4723 - accuracy: 0.5470 - val_loss: 0.5413 - val_accuracy: 0.5209\n",
            "Epoch 74/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4720 - accuracy: 0.5471 - val_loss: 0.5410 - val_accuracy: 0.5215\n",
            "Epoch 75/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4716 - accuracy: 0.5478 - val_loss: 0.5412 - val_accuracy: 0.5215\n",
            "Epoch 76/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4710 - accuracy: 0.5485 - val_loss: 0.5396 - val_accuracy: 0.5211\n",
            "Epoch 77/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4701 - accuracy: 0.5487 - val_loss: 0.5405 - val_accuracy: 0.5217\n",
            "Epoch 78/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4699 - accuracy: 0.5496 - val_loss: 0.5399 - val_accuracy: 0.5211\n",
            "Epoch 79/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4691 - accuracy: 0.5494 - val_loss: 0.5408 - val_accuracy: 0.5228\n",
            "Epoch 80/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4686 - accuracy: 0.5503 - val_loss: 0.5411 - val_accuracy: 0.5233\n",
            "Epoch 81/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4681 - accuracy: 0.5502 - val_loss: 0.5400 - val_accuracy: 0.5217\n",
            "Epoch 82/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4676 - accuracy: 0.5502 - val_loss: 0.5398 - val_accuracy: 0.5228\n",
            "Epoch 83/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4669 - accuracy: 0.5517 - val_loss: 0.5402 - val_accuracy: 0.5231\n",
            "Epoch 84/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4662 - accuracy: 0.5521 - val_loss: 0.5399 - val_accuracy: 0.5233\n",
            "Epoch 85/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4657 - accuracy: 0.5530 - val_loss: 0.5413 - val_accuracy: 0.5248\n",
            "Epoch 86/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4653 - accuracy: 0.5532 - val_loss: 0.5397 - val_accuracy: 0.5246\n",
            "Epoch 87/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4693 - accuracy: 0.5517 - val_loss: 0.5416 - val_accuracy: 0.5226\n",
            "Epoch 88/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4676 - accuracy: 0.5532 - val_loss: 0.5419 - val_accuracy: 0.5243\n",
            "Epoch 89/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4658 - accuracy: 0.5535 - val_loss: 0.5410 - val_accuracy: 0.5246\n",
            "Epoch 90/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4648 - accuracy: 0.5538 - val_loss: 0.5404 - val_accuracy: 0.5246\n",
            "Epoch 91/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4638 - accuracy: 0.5547 - val_loss: 0.5409 - val_accuracy: 0.5252\n",
            "Epoch 92/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4634 - accuracy: 0.5551 - val_loss: 0.5404 - val_accuracy: 0.5256\n",
            "Epoch 93/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4625 - accuracy: 0.5558 - val_loss: 0.5406 - val_accuracy: 0.5259\n",
            "Epoch 94/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4620 - accuracy: 0.5557 - val_loss: 0.5403 - val_accuracy: 0.5265\n",
            "Epoch 95/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4612 - accuracy: 0.5569 - val_loss: 0.5402 - val_accuracy: 0.5270\n",
            "Epoch 96/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4610 - accuracy: 0.5572 - val_loss: 0.5409 - val_accuracy: 0.5270\n",
            "Epoch 97/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4607 - accuracy: 0.5575 - val_loss: 0.5403 - val_accuracy: 0.5267\n",
            "Epoch 98/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4600 - accuracy: 0.5575 - val_loss: 0.5401 - val_accuracy: 0.5285\n",
            "Epoch 99/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4595 - accuracy: 0.5580 - val_loss: 0.5400 - val_accuracy: 0.5285\n",
            "Epoch 100/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4592 - accuracy: 0.5590 - val_loss: 0.5396 - val_accuracy: 0.5274\n",
            "Training time finished.\n",
            "100 epochs in        80.16 sec\n",
            "0.5274(max: 0.5285)\n",
            "Size dataframe: 18000 records\n",
            "Size training: 12600 records\n",
            "Size validation: 5400 records\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What would you like to do?\n",
            " 0 - Leave\n",
            " 1 - Data Structure\n",
            " 2 - Train\n",
            " 3 - Predict\n",
            "2\n",
            "\u001b[H\u001b[2JEnter the name of the training file located inside the /data/training: training-36000-sentences.csv\n",
            "Enter the percent of validation between 0% and 30%: 30\n",
            "Enter the number of epochs to train: 100\n",
            "Enter the number of max sequence length to train: 5\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Loading word2vec model (it may takes around 2-3 minutes)...\n",
            "tcmalloc: large alloc 3600007168 bytes == 0xf239e000 @  0x7efee68d0001 0x7efee2cd9765 0x7efee2d3ddc0 0x7efee2d3fc5f 0x7efee2dd6238 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "word2vec loaded\n",
            "1,000 sentences embedded.\n",
            "2,000 sentences embedded.\n",
            "3,000 sentences embedded.\n",
            "4,000 sentences embedded.\n",
            "5,000 sentences embedded.\n",
            "6,000 sentences embedded.\n",
            "7,000 sentences embedded.\n",
            "8,000 sentences embedded.\n",
            "9,000 sentences embedded.\n",
            "10,000 sentences embedded.\n",
            "11,000 sentences embedded.\n",
            "12,000 sentences embedded.\n",
            "13,000 sentences embedded.\n",
            "14,000 sentences embedded.\n",
            "15,000 sentences embedded.\n",
            "16,000 sentences embedded.\n",
            "17,000 sentences embedded.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 50)           4350600     input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "manhattan_distance_1 (Manhattan (None, 1)            0           sequential_1[1][0]               \n",
            "                                                                 sequential_1[2][0]               \n",
            "==================================================================================================\n",
            "Total params: 4,350,600\n",
            "Trainable params: 70,200\n",
            "Non-trainable params: 4,280,400\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "99/99 [==============================] - 1s 12ms/step - loss: 1.1418 - accuracy: 0.3580 - val_loss: 0.8465 - val_accuracy: 0.3785\n",
            "Epoch 2/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.7753 - accuracy: 0.3797 - val_loss: 0.7336 - val_accuracy: 0.3852\n",
            "Epoch 3/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6978 - accuracy: 0.3848 - val_loss: 0.6924 - val_accuracy: 0.3891\n",
            "Epoch 4/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6631 - accuracy: 0.3894 - val_loss: 0.6702 - val_accuracy: 0.3944\n",
            "Epoch 5/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.6432 - accuracy: 0.3943 - val_loss: 0.6560 - val_accuracy: 0.4004\n",
            "Epoch 6/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.6296 - accuracy: 0.4048 - val_loss: 0.6460 - val_accuracy: 0.4117\n",
            "Epoch 7/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6191 - accuracy: 0.4128 - val_loss: 0.6375 - val_accuracy: 0.4165\n",
            "Epoch 8/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6096 - accuracy: 0.4183 - val_loss: 0.6312 - val_accuracy: 0.4181\n",
            "Epoch 9/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6028 - accuracy: 0.4214 - val_loss: 0.6247 - val_accuracy: 0.4219\n",
            "Epoch 10/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5961 - accuracy: 0.4252 - val_loss: 0.6206 - val_accuracy: 0.4269\n",
            "Epoch 11/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5907 - accuracy: 0.4310 - val_loss: 0.6154 - val_accuracy: 0.4276\n",
            "Epoch 12/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5854 - accuracy: 0.4347 - val_loss: 0.6119 - val_accuracy: 0.4298\n",
            "Epoch 13/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5806 - accuracy: 0.4386 - val_loss: 0.6064 - val_accuracy: 0.4376\n",
            "Epoch 14/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5724 - accuracy: 0.4472 - val_loss: 0.5996 - val_accuracy: 0.4481\n",
            "Epoch 15/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5647 - accuracy: 0.4598 - val_loss: 0.5930 - val_accuracy: 0.4600\n",
            "Epoch 16/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5566 - accuracy: 0.4720 - val_loss: 0.5882 - val_accuracy: 0.4661\n",
            "Epoch 17/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5501 - accuracy: 0.4795 - val_loss: 0.5858 - val_accuracy: 0.4835\n",
            "Epoch 18/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5450 - accuracy: 0.4858 - val_loss: 0.5819 - val_accuracy: 0.4809\n",
            "Epoch 19/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5410 - accuracy: 0.4912 - val_loss: 0.5784 - val_accuracy: 0.4828\n",
            "Epoch 20/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5370 - accuracy: 0.4969 - val_loss: 0.5772 - val_accuracy: 0.4904\n",
            "Epoch 21/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5339 - accuracy: 0.5006 - val_loss: 0.5751 - val_accuracy: 0.4915\n",
            "Epoch 22/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5309 - accuracy: 0.5033 - val_loss: 0.5725 - val_accuracy: 0.4935\n",
            "Epoch 23/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5282 - accuracy: 0.5044 - val_loss: 0.5712 - val_accuracy: 0.4937\n",
            "Epoch 24/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5262 - accuracy: 0.5054 - val_loss: 0.5702 - val_accuracy: 0.4935\n",
            "Epoch 25/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5246 - accuracy: 0.5066 - val_loss: 0.5680 - val_accuracy: 0.4943\n",
            "Epoch 26/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5216 - accuracy: 0.5079 - val_loss: 0.5671 - val_accuracy: 0.4965\n",
            "Epoch 27/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5212 - accuracy: 0.5093 - val_loss: 0.5672 - val_accuracy: 0.4957\n",
            "Epoch 28/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5195 - accuracy: 0.5104 - val_loss: 0.5675 - val_accuracy: 0.4978\n",
            "Epoch 29/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5171 - accuracy: 0.5120 - val_loss: 0.5665 - val_accuracy: 0.5004\n",
            "Epoch 30/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5171 - accuracy: 0.5131 - val_loss: 0.5656 - val_accuracy: 0.5015\n",
            "Epoch 31/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5147 - accuracy: 0.5149 - val_loss: 0.5640 - val_accuracy: 0.5024\n",
            "Epoch 32/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5115 - accuracy: 0.5167 - val_loss: 0.5635 - val_accuracy: 0.5017\n",
            "Epoch 33/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5092 - accuracy: 0.5179 - val_loss: 0.5623 - val_accuracy: 0.5041\n",
            "Epoch 34/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5078 - accuracy: 0.5197 - val_loss: 0.5613 - val_accuracy: 0.5035\n",
            "Epoch 35/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5064 - accuracy: 0.5193 - val_loss: 0.5607 - val_accuracy: 0.5056\n",
            "Epoch 36/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5049 - accuracy: 0.5202 - val_loss: 0.5597 - val_accuracy: 0.5054\n",
            "Epoch 37/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5036 - accuracy: 0.5217 - val_loss: 0.5596 - val_accuracy: 0.5059\n",
            "Epoch 38/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5027 - accuracy: 0.5222 - val_loss: 0.5602 - val_accuracy: 0.5065\n",
            "Epoch 39/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5019 - accuracy: 0.5234 - val_loss: 0.5581 - val_accuracy: 0.5054\n",
            "Epoch 40/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5012 - accuracy: 0.5237 - val_loss: 0.5578 - val_accuracy: 0.5057\n",
            "Epoch 41/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4998 - accuracy: 0.5248 - val_loss: 0.5575 - val_accuracy: 0.5085\n",
            "Epoch 42/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4984 - accuracy: 0.5256 - val_loss: 0.5572 - val_accuracy: 0.5091\n",
            "Epoch 43/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4973 - accuracy: 0.5262 - val_loss: 0.5571 - val_accuracy: 0.5104\n",
            "Epoch 44/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4961 - accuracy: 0.5264 - val_loss: 0.5555 - val_accuracy: 0.5119\n",
            "Epoch 45/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4949 - accuracy: 0.5279 - val_loss: 0.5543 - val_accuracy: 0.5126\n",
            "Epoch 46/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4944 - accuracy: 0.5283 - val_loss: 0.5541 - val_accuracy: 0.5130\n",
            "Epoch 47/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4929 - accuracy: 0.5293 - val_loss: 0.5537 - val_accuracy: 0.5115\n",
            "Epoch 48/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4917 - accuracy: 0.5299 - val_loss: 0.5537 - val_accuracy: 0.5131\n",
            "Epoch 49/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4918 - accuracy: 0.5300 - val_loss: 0.5532 - val_accuracy: 0.5128\n",
            "Epoch 50/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4894 - accuracy: 0.5308 - val_loss: 0.5522 - val_accuracy: 0.5139\n",
            "Epoch 51/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4887 - accuracy: 0.5313 - val_loss: 0.5525 - val_accuracy: 0.5143\n",
            "Epoch 52/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4879 - accuracy: 0.5321 - val_loss: 0.5527 - val_accuracy: 0.5144\n",
            "Epoch 53/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4873 - accuracy: 0.5320 - val_loss: 0.5531 - val_accuracy: 0.5169\n",
            "Epoch 54/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4864 - accuracy: 0.5340 - val_loss: 0.5527 - val_accuracy: 0.5169\n",
            "Epoch 55/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4857 - accuracy: 0.5344 - val_loss: 0.5524 - val_accuracy: 0.5176\n",
            "Epoch 56/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4847 - accuracy: 0.5360 - val_loss: 0.5525 - val_accuracy: 0.5174\n",
            "Epoch 57/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4840 - accuracy: 0.5368 - val_loss: 0.5525 - val_accuracy: 0.5180\n",
            "Epoch 58/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4835 - accuracy: 0.5375 - val_loss: 0.5522 - val_accuracy: 0.5178\n",
            "Epoch 59/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4826 - accuracy: 0.5379 - val_loss: 0.5513 - val_accuracy: 0.5187\n",
            "Epoch 60/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4821 - accuracy: 0.5393 - val_loss: 0.5508 - val_accuracy: 0.5181\n",
            "Epoch 61/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4840 - accuracy: 0.5397 - val_loss: 0.5547 - val_accuracy: 0.5174\n",
            "Epoch 62/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4840 - accuracy: 0.5379 - val_loss: 0.5545 - val_accuracy: 0.5174\n",
            "Epoch 63/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4827 - accuracy: 0.5398 - val_loss: 0.5527 - val_accuracy: 0.5183\n",
            "Epoch 64/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4812 - accuracy: 0.5406 - val_loss: 0.5507 - val_accuracy: 0.5187\n",
            "Epoch 65/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4803 - accuracy: 0.5417 - val_loss: 0.5536 - val_accuracy: 0.5196\n",
            "Epoch 66/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4800 - accuracy: 0.5420 - val_loss: 0.5506 - val_accuracy: 0.5204\n",
            "Epoch 67/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4795 - accuracy: 0.5421 - val_loss: 0.5528 - val_accuracy: 0.5202\n",
            "Epoch 68/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4803 - accuracy: 0.5421 - val_loss: 0.5519 - val_accuracy: 0.5207\n",
            "Epoch 69/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4781 - accuracy: 0.5430 - val_loss: 0.5516 - val_accuracy: 0.5217\n",
            "Epoch 70/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4774 - accuracy: 0.5436 - val_loss: 0.5508 - val_accuracy: 0.5215\n",
            "Epoch 71/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4769 - accuracy: 0.5439 - val_loss: 0.5506 - val_accuracy: 0.5219\n",
            "Epoch 72/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4760 - accuracy: 0.5450 - val_loss: 0.5506 - val_accuracy: 0.5217\n",
            "Epoch 73/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4756 - accuracy: 0.5452 - val_loss: 0.5510 - val_accuracy: 0.5222\n",
            "Epoch 74/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4751 - accuracy: 0.5454 - val_loss: 0.5502 - val_accuracy: 0.5220\n",
            "Epoch 75/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4742 - accuracy: 0.5461 - val_loss: 0.5506 - val_accuracy: 0.5222\n",
            "Epoch 76/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4737 - accuracy: 0.5465 - val_loss: 0.5502 - val_accuracy: 0.5224\n",
            "Epoch 77/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4734 - accuracy: 0.5467 - val_loss: 0.5518 - val_accuracy: 0.5228\n",
            "Epoch 78/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4728 - accuracy: 0.5479 - val_loss: 0.5503 - val_accuracy: 0.5224\n",
            "Epoch 79/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4714 - accuracy: 0.5475 - val_loss: 0.5513 - val_accuracy: 0.5226\n",
            "Epoch 80/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4717 - accuracy: 0.5481 - val_loss: 0.5508 - val_accuracy: 0.5220\n",
            "Epoch 81/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4711 - accuracy: 0.5491 - val_loss: 0.5505 - val_accuracy: 0.5228\n",
            "Epoch 82/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4705 - accuracy: 0.5491 - val_loss: 0.5528 - val_accuracy: 0.5231\n",
            "Epoch 83/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4707 - accuracy: 0.5495 - val_loss: 0.5493 - val_accuracy: 0.5222\n",
            "Epoch 84/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4694 - accuracy: 0.5501 - val_loss: 0.5509 - val_accuracy: 0.5233\n",
            "Epoch 85/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4687 - accuracy: 0.5503 - val_loss: 0.5508 - val_accuracy: 0.5233\n",
            "Epoch 86/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4686 - accuracy: 0.5514 - val_loss: 0.5498 - val_accuracy: 0.5231\n",
            "Epoch 87/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4678 - accuracy: 0.5514 - val_loss: 0.5501 - val_accuracy: 0.5228\n",
            "Epoch 88/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4673 - accuracy: 0.5517 - val_loss: 0.5501 - val_accuracy: 0.5233\n",
            "Epoch 89/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4672 - accuracy: 0.5524 - val_loss: 0.5508 - val_accuracy: 0.5235\n",
            "Epoch 90/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4672 - accuracy: 0.5529 - val_loss: 0.5504 - val_accuracy: 0.5235\n",
            "Epoch 91/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4666 - accuracy: 0.5530 - val_loss: 0.5506 - val_accuracy: 0.5244\n",
            "Epoch 92/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4660 - accuracy: 0.5534 - val_loss: 0.5497 - val_accuracy: 0.5243\n",
            "Epoch 93/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4657 - accuracy: 0.5540 - val_loss: 0.5529 - val_accuracy: 0.5241\n",
            "Epoch 94/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4655 - accuracy: 0.5540 - val_loss: 0.5514 - val_accuracy: 0.5246\n",
            "Epoch 95/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4651 - accuracy: 0.5547 - val_loss: 0.5509 - val_accuracy: 0.5243\n",
            "Epoch 96/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4662 - accuracy: 0.5544 - val_loss: 0.5525 - val_accuracy: 0.5241\n",
            "Epoch 97/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4654 - accuracy: 0.5548 - val_loss: 0.5512 - val_accuracy: 0.5241\n",
            "Epoch 98/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4645 - accuracy: 0.5555 - val_loss: 0.5506 - val_accuracy: 0.5244\n",
            "Epoch 99/100\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4640 - accuracy: 0.5556 - val_loss: 0.5506 - val_accuracy: 0.5248\n",
            "Epoch 100/100\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4636 - accuracy: 0.5563 - val_loss: 0.5505 - val_accuracy: 0.5250\n",
            "Training time finished.\n",
            "100 epochs in        76.02 sec\n",
            "0.5249(max: 0.5249)\n",
            "Size dataframe: 18000 records\n",
            "Size training: 12600 records\n",
            "Size validation: 5400 records\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What would you like to do?\n",
            " 0 - Leave\n",
            " 1 - Data Structure\n",
            " 2 - Train\n",
            " 3 - Predict\n",
            "2\n",
            "\u001b[H\u001b[2JEnter the name of the training file located inside the /data/training: training-36000-sentences.csv\n",
            "Enter the percent of validation between 0% and 30%: 30\n",
            "Enter the number of epochs to train: 500\n",
            "Enter the number of max sequence length to train: 5\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Loading word2vec model (it may takes around 2-3 minutes)...\n",
            "tcmalloc: large alloc 3600007168 bytes == 0xf239e000 @  0x7efee68d0001 0x7efee2cd9765 0x7efee2d3ddc0 0x7efee2d3fc5f 0x7efee2dd6238 0x50a4a5 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd 0x50beb4 0x5095c8 0x50a2fd\n",
            "word2vec loaded\n",
            "1,000 sentences embedded.\n",
            "2,000 sentences embedded.\n",
            "3,000 sentences embedded.\n",
            "4,000 sentences embedded.\n",
            "5,000 sentences embedded.\n",
            "6,000 sentences embedded.\n",
            "7,000 sentences embedded.\n",
            "8,000 sentences embedded.\n",
            "9,000 sentences embedded.\n",
            "10,000 sentences embedded.\n",
            "11,000 sentences embedded.\n",
            "12,000 sentences embedded.\n",
            "13,000 sentences embedded.\n",
            "14,000 sentences embedded.\n",
            "15,000 sentences embedded.\n",
            "16,000 sentences embedded.\n",
            "17,000 sentences embedded.\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 50)           4350600     input_5[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "manhattan_distance_2 (Manhattan (None, 1)            0           sequential_2[1][0]               \n",
            "                                                                 sequential_2[2][0]               \n",
            "==================================================================================================\n",
            "Total params: 4,350,600\n",
            "Trainable params: 70,200\n",
            "Non-trainable params: 4,280,400\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/500\n",
            "99/99 [==============================] - 1s 13ms/step - loss: 1.1409 - accuracy: 0.3599 - val_loss: 0.8454 - val_accuracy: 0.3883\n",
            "Epoch 2/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.7772 - accuracy: 0.3783 - val_loss: 0.7328 - val_accuracy: 0.3817\n",
            "Epoch 3/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.7036 - accuracy: 0.3816 - val_loss: 0.6912 - val_accuracy: 0.3881\n",
            "Epoch 4/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6695 - accuracy: 0.3868 - val_loss: 0.6658 - val_accuracy: 0.3944\n",
            "Epoch 5/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6486 - accuracy: 0.3933 - val_loss: 0.6495 - val_accuracy: 0.4004\n",
            "Epoch 6/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.6338 - accuracy: 0.3999 - val_loss: 0.6366 - val_accuracy: 0.4091\n",
            "Epoch 7/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6220 - accuracy: 0.4078 - val_loss: 0.6274 - val_accuracy: 0.4135\n",
            "Epoch 8/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.6137 - accuracy: 0.4120 - val_loss: 0.6202 - val_accuracy: 0.4156\n",
            "Epoch 9/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6059 - accuracy: 0.4144 - val_loss: 0.6159 - val_accuracy: 0.4156\n",
            "Epoch 10/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.6003 - accuracy: 0.4186 - val_loss: 0.6107 - val_accuracy: 0.4215\n",
            "Epoch 11/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5949 - accuracy: 0.4223 - val_loss: 0.6074 - val_accuracy: 0.4246\n",
            "Epoch 12/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5896 - accuracy: 0.4271 - val_loss: 0.6024 - val_accuracy: 0.4328\n",
            "Epoch 13/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5851 - accuracy: 0.4329 - val_loss: 0.5988 - val_accuracy: 0.4348\n",
            "Epoch 14/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5796 - accuracy: 0.4371 - val_loss: 0.5958 - val_accuracy: 0.4374\n",
            "Epoch 15/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5749 - accuracy: 0.4418 - val_loss: 0.5924 - val_accuracy: 0.4398\n",
            "Epoch 16/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5701 - accuracy: 0.4455 - val_loss: 0.5884 - val_accuracy: 0.4485\n",
            "Epoch 17/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5649 - accuracy: 0.4479 - val_loss: 0.5844 - val_accuracy: 0.4509\n",
            "Epoch 18/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5599 - accuracy: 0.4525 - val_loss: 0.5807 - val_accuracy: 0.4587\n",
            "Epoch 19/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5552 - accuracy: 0.4563 - val_loss: 0.5769 - val_accuracy: 0.4628\n",
            "Epoch 20/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5499 - accuracy: 0.4667 - val_loss: 0.5730 - val_accuracy: 0.4609\n",
            "Epoch 21/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5453 - accuracy: 0.4697 - val_loss: 0.5695 - val_accuracy: 0.4761\n",
            "Epoch 22/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5402 - accuracy: 0.4783 - val_loss: 0.5653 - val_accuracy: 0.4757\n",
            "Epoch 23/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5364 - accuracy: 0.4817 - val_loss: 0.5628 - val_accuracy: 0.4839\n",
            "Epoch 24/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5328 - accuracy: 0.4889 - val_loss: 0.5610 - val_accuracy: 0.4867\n",
            "Epoch 25/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5294 - accuracy: 0.4906 - val_loss: 0.5591 - val_accuracy: 0.4900\n",
            "Epoch 26/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5273 - accuracy: 0.4943 - val_loss: 0.5587 - val_accuracy: 0.4924\n",
            "Epoch 27/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5246 - accuracy: 0.4969 - val_loss: 0.5564 - val_accuracy: 0.4928\n",
            "Epoch 28/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5220 - accuracy: 0.4986 - val_loss: 0.5545 - val_accuracy: 0.4956\n",
            "Epoch 29/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5197 - accuracy: 0.5013 - val_loss: 0.5530 - val_accuracy: 0.4963\n",
            "Epoch 30/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5179 - accuracy: 0.5025 - val_loss: 0.5524 - val_accuracy: 0.4987\n",
            "Epoch 31/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5157 - accuracy: 0.5052 - val_loss: 0.5517 - val_accuracy: 0.5000\n",
            "Epoch 32/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5144 - accuracy: 0.5063 - val_loss: 0.5504 - val_accuracy: 0.5024\n",
            "Epoch 33/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5120 - accuracy: 0.5080 - val_loss: 0.5494 - val_accuracy: 0.5028\n",
            "Epoch 34/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5102 - accuracy: 0.5091 - val_loss: 0.5478 - val_accuracy: 0.5024\n",
            "Epoch 35/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5087 - accuracy: 0.5102 - val_loss: 0.5466 - val_accuracy: 0.5044\n",
            "Epoch 36/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5074 - accuracy: 0.5120 - val_loss: 0.5464 - val_accuracy: 0.5046\n",
            "Epoch 37/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5064 - accuracy: 0.5124 - val_loss: 0.5468 - val_accuracy: 0.5059\n",
            "Epoch 38/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.5054 - accuracy: 0.5137 - val_loss: 0.5459 - val_accuracy: 0.5057\n",
            "Epoch 39/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5037 - accuracy: 0.5152 - val_loss: 0.5455 - val_accuracy: 0.5072\n",
            "Epoch 40/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5021 - accuracy: 0.5154 - val_loss: 0.5440 - val_accuracy: 0.5085\n",
            "Epoch 41/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.5003 - accuracy: 0.5176 - val_loss: 0.5432 - val_accuracy: 0.5091\n",
            "Epoch 42/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4987 - accuracy: 0.5183 - val_loss: 0.5421 - val_accuracy: 0.5089\n",
            "Epoch 43/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4975 - accuracy: 0.5186 - val_loss: 0.5416 - val_accuracy: 0.5104\n",
            "Epoch 44/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4966 - accuracy: 0.5204 - val_loss: 0.5406 - val_accuracy: 0.5106\n",
            "Epoch 45/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4952 - accuracy: 0.5206 - val_loss: 0.5402 - val_accuracy: 0.5107\n",
            "Epoch 46/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4943 - accuracy: 0.5210 - val_loss: 0.5396 - val_accuracy: 0.5113\n",
            "Epoch 47/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4932 - accuracy: 0.5220 - val_loss: 0.5385 - val_accuracy: 0.5119\n",
            "Epoch 48/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4921 - accuracy: 0.5229 - val_loss: 0.5391 - val_accuracy: 0.5139\n",
            "Epoch 49/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4916 - accuracy: 0.5240 - val_loss: 0.5379 - val_accuracy: 0.5130\n",
            "Epoch 50/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4905 - accuracy: 0.5259 - val_loss: 0.5380 - val_accuracy: 0.5141\n",
            "Epoch 51/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4892 - accuracy: 0.5262 - val_loss: 0.5372 - val_accuracy: 0.5159\n",
            "Epoch 52/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4883 - accuracy: 0.5279 - val_loss: 0.5367 - val_accuracy: 0.5161\n",
            "Epoch 53/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4872 - accuracy: 0.5287 - val_loss: 0.5354 - val_accuracy: 0.5161\n",
            "Epoch 54/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4859 - accuracy: 0.5303 - val_loss: 0.5366 - val_accuracy: 0.5181\n",
            "Epoch 55/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4858 - accuracy: 0.5310 - val_loss: 0.5362 - val_accuracy: 0.5178\n",
            "Epoch 56/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4865 - accuracy: 0.5324 - val_loss: 0.5379 - val_accuracy: 0.5174\n",
            "Epoch 57/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4861 - accuracy: 0.5327 - val_loss: 0.5351 - val_accuracy: 0.5200\n",
            "Epoch 58/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4835 - accuracy: 0.5337 - val_loss: 0.5345 - val_accuracy: 0.5211\n",
            "Epoch 59/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4822 - accuracy: 0.5348 - val_loss: 0.5330 - val_accuracy: 0.5213\n",
            "Epoch 60/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4808 - accuracy: 0.5356 - val_loss: 0.5325 - val_accuracy: 0.5213\n",
            "Epoch 61/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4796 - accuracy: 0.5365 - val_loss: 0.5343 - val_accuracy: 0.5267\n",
            "Epoch 62/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4794 - accuracy: 0.5369 - val_loss: 0.5319 - val_accuracy: 0.5217\n",
            "Epoch 63/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4780 - accuracy: 0.5370 - val_loss: 0.5319 - val_accuracy: 0.5233\n",
            "Epoch 64/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4772 - accuracy: 0.5383 - val_loss: 0.5306 - val_accuracy: 0.5239\n",
            "Epoch 65/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4762 - accuracy: 0.5388 - val_loss: 0.5308 - val_accuracy: 0.5243\n",
            "Epoch 66/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4754 - accuracy: 0.5398 - val_loss: 0.5304 - val_accuracy: 0.5248\n",
            "Epoch 67/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4749 - accuracy: 0.5408 - val_loss: 0.5294 - val_accuracy: 0.5231\n",
            "Epoch 68/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4740 - accuracy: 0.5418 - val_loss: 0.5309 - val_accuracy: 0.5272\n",
            "Epoch 69/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4740 - accuracy: 0.5428 - val_loss: 0.5310 - val_accuracy: 0.5254\n",
            "Epoch 70/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4745 - accuracy: 0.5415 - val_loss: 0.5297 - val_accuracy: 0.5244\n",
            "Epoch 71/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4748 - accuracy: 0.5429 - val_loss: 0.5314 - val_accuracy: 0.5241\n",
            "Epoch 72/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4743 - accuracy: 0.5426 - val_loss: 0.5303 - val_accuracy: 0.5256\n",
            "Epoch 73/500\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.4748 - accuracy: 0.5429 - val_loss: 0.5332 - val_accuracy: 0.5239\n",
            "Epoch 74/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4733 - accuracy: 0.5440 - val_loss: 0.5318 - val_accuracy: 0.5265\n",
            "Epoch 75/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4712 - accuracy: 0.5448 - val_loss: 0.5313 - val_accuracy: 0.5259\n",
            "Epoch 76/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4708 - accuracy: 0.5466 - val_loss: 0.5307 - val_accuracy: 0.5272\n",
            "Epoch 77/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4699 - accuracy: 0.5465 - val_loss: 0.5305 - val_accuracy: 0.5274\n",
            "Epoch 78/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4693 - accuracy: 0.5472 - val_loss: 0.5306 - val_accuracy: 0.5256\n",
            "Epoch 79/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4691 - accuracy: 0.5471 - val_loss: 0.5300 - val_accuracy: 0.5269\n",
            "Epoch 80/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4684 - accuracy: 0.5478 - val_loss: 0.5296 - val_accuracy: 0.5285\n",
            "Epoch 81/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4677 - accuracy: 0.5487 - val_loss: 0.5295 - val_accuracy: 0.5302\n",
            "Epoch 82/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4670 - accuracy: 0.5487 - val_loss: 0.5289 - val_accuracy: 0.5285\n",
            "Epoch 83/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4661 - accuracy: 0.5494 - val_loss: 0.5290 - val_accuracy: 0.5304\n",
            "Epoch 84/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4663 - accuracy: 0.5496 - val_loss: 0.5295 - val_accuracy: 0.5306\n",
            "Epoch 85/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4653 - accuracy: 0.5501 - val_loss: 0.5294 - val_accuracy: 0.5306\n",
            "Epoch 86/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4652 - accuracy: 0.5502 - val_loss: 0.5289 - val_accuracy: 0.5306\n",
            "Epoch 87/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4648 - accuracy: 0.5514 - val_loss: 0.5291 - val_accuracy: 0.5306\n",
            "Epoch 88/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4645 - accuracy: 0.5513 - val_loss: 0.5298 - val_accuracy: 0.5320\n",
            "Epoch 89/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4641 - accuracy: 0.5516 - val_loss: 0.5283 - val_accuracy: 0.5309\n",
            "Epoch 90/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4635 - accuracy: 0.5532 - val_loss: 0.5292 - val_accuracy: 0.5307\n",
            "Epoch 91/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4628 - accuracy: 0.5530 - val_loss: 0.5291 - val_accuracy: 0.5317\n",
            "Epoch 92/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4629 - accuracy: 0.5542 - val_loss: 0.5303 - val_accuracy: 0.5317\n",
            "Epoch 93/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4622 - accuracy: 0.5536 - val_loss: 0.5294 - val_accuracy: 0.5317\n",
            "Epoch 94/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4620 - accuracy: 0.5548 - val_loss: 0.5304 - val_accuracy: 0.5326\n",
            "Epoch 95/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4618 - accuracy: 0.5540 - val_loss: 0.5295 - val_accuracy: 0.5311\n",
            "Epoch 96/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4611 - accuracy: 0.5552 - val_loss: 0.5307 - val_accuracy: 0.5317\n",
            "Epoch 97/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4611 - accuracy: 0.5559 - val_loss: 0.5316 - val_accuracy: 0.5322\n",
            "Epoch 98/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4609 - accuracy: 0.5557 - val_loss: 0.5301 - val_accuracy: 0.5313\n",
            "Epoch 99/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4603 - accuracy: 0.5560 - val_loss: 0.5306 - val_accuracy: 0.5317\n",
            "Epoch 100/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4597 - accuracy: 0.5571 - val_loss: 0.5301 - val_accuracy: 0.5320\n",
            "Epoch 101/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4591 - accuracy: 0.5572 - val_loss: 0.5303 - val_accuracy: 0.5335\n",
            "Epoch 102/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4584 - accuracy: 0.5582 - val_loss: 0.5313 - val_accuracy: 0.5333\n",
            "Epoch 103/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4590 - accuracy: 0.5581 - val_loss: 0.5307 - val_accuracy: 0.5333\n",
            "Epoch 104/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4580 - accuracy: 0.5589 - val_loss: 0.5309 - val_accuracy: 0.5317\n",
            "Epoch 105/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4576 - accuracy: 0.5579 - val_loss: 0.5307 - val_accuracy: 0.5339\n",
            "Epoch 106/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4574 - accuracy: 0.5592 - val_loss: 0.5313 - val_accuracy: 0.5339\n",
            "Epoch 107/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4571 - accuracy: 0.5588 - val_loss: 0.5318 - val_accuracy: 0.5363\n",
            "Epoch 108/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4569 - accuracy: 0.5588 - val_loss: 0.5303 - val_accuracy: 0.5346\n",
            "Epoch 109/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4565 - accuracy: 0.5594 - val_loss: 0.5313 - val_accuracy: 0.5367\n",
            "Epoch 110/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4559 - accuracy: 0.5610 - val_loss: 0.5332 - val_accuracy: 0.5367\n",
            "Epoch 111/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4563 - accuracy: 0.5599 - val_loss: 0.5309 - val_accuracy: 0.5344\n",
            "Epoch 112/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4553 - accuracy: 0.5607 - val_loss: 0.5330 - val_accuracy: 0.5356\n",
            "Epoch 113/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4549 - accuracy: 0.5620 - val_loss: 0.5310 - val_accuracy: 0.5365\n",
            "Epoch 114/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4545 - accuracy: 0.5621 - val_loss: 0.5314 - val_accuracy: 0.5363\n",
            "Epoch 115/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4543 - accuracy: 0.5620 - val_loss: 0.5322 - val_accuracy: 0.5378\n",
            "Epoch 116/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4536 - accuracy: 0.5631 - val_loss: 0.5313 - val_accuracy: 0.5363\n",
            "Epoch 117/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4541 - accuracy: 0.5623 - val_loss: 0.5312 - val_accuracy: 0.5350\n",
            "Epoch 118/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4535 - accuracy: 0.5635 - val_loss: 0.5313 - val_accuracy: 0.5359\n",
            "Epoch 119/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4540 - accuracy: 0.5635 - val_loss: 0.5320 - val_accuracy: 0.5363\n",
            "Epoch 120/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4529 - accuracy: 0.5637 - val_loss: 0.5318 - val_accuracy: 0.5363\n",
            "Epoch 121/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4525 - accuracy: 0.5641 - val_loss: 0.5342 - val_accuracy: 0.5372\n",
            "Epoch 122/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4522 - accuracy: 0.5648 - val_loss: 0.5318 - val_accuracy: 0.5361\n",
            "Epoch 123/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4529 - accuracy: 0.5642 - val_loss: 0.5317 - val_accuracy: 0.5363\n",
            "Epoch 124/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4520 - accuracy: 0.5649 - val_loss: 0.5307 - val_accuracy: 0.5361\n",
            "Epoch 125/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4515 - accuracy: 0.5656 - val_loss: 0.5313 - val_accuracy: 0.5365\n",
            "Epoch 126/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4512 - accuracy: 0.5657 - val_loss: 0.5319 - val_accuracy: 0.5369\n",
            "Epoch 127/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4510 - accuracy: 0.5654 - val_loss: 0.5310 - val_accuracy: 0.5367\n",
            "Epoch 128/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4508 - accuracy: 0.5668 - val_loss: 0.5308 - val_accuracy: 0.5367\n",
            "Epoch 129/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4501 - accuracy: 0.5659 - val_loss: 0.5308 - val_accuracy: 0.5370\n",
            "Epoch 130/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4502 - accuracy: 0.5672 - val_loss: 0.5311 - val_accuracy: 0.5378\n",
            "Epoch 131/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4498 - accuracy: 0.5668 - val_loss: 0.5311 - val_accuracy: 0.5370\n",
            "Epoch 132/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4522 - accuracy: 0.5660 - val_loss: 0.5349 - val_accuracy: 0.5337\n",
            "Epoch 133/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4522 - accuracy: 0.5663 - val_loss: 0.5335 - val_accuracy: 0.5354\n",
            "Epoch 134/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4507 - accuracy: 0.5674 - val_loss: 0.5327 - val_accuracy: 0.5359\n",
            "Epoch 135/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4496 - accuracy: 0.5679 - val_loss: 0.5322 - val_accuracy: 0.5376\n",
            "Epoch 136/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4489 - accuracy: 0.5685 - val_loss: 0.5335 - val_accuracy: 0.5370\n",
            "Epoch 137/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4488 - accuracy: 0.5687 - val_loss: 0.5320 - val_accuracy: 0.5352\n",
            "Epoch 138/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4484 - accuracy: 0.5683 - val_loss: 0.5324 - val_accuracy: 0.5380\n",
            "Epoch 139/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4483 - accuracy: 0.5686 - val_loss: 0.5322 - val_accuracy: 0.5365\n",
            "Epoch 140/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4475 - accuracy: 0.5699 - val_loss: 0.5328 - val_accuracy: 0.5380\n",
            "Epoch 141/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4475 - accuracy: 0.5700 - val_loss: 0.5320 - val_accuracy: 0.5367\n",
            "Epoch 142/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4475 - accuracy: 0.5692 - val_loss: 0.5333 - val_accuracy: 0.5380\n",
            "Epoch 143/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4470 - accuracy: 0.5703 - val_loss: 0.5336 - val_accuracy: 0.5380\n",
            "Epoch 144/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4468 - accuracy: 0.5704 - val_loss: 0.5322 - val_accuracy: 0.5376\n",
            "Epoch 145/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4464 - accuracy: 0.5711 - val_loss: 0.5324 - val_accuracy: 0.5374\n",
            "Epoch 146/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4463 - accuracy: 0.5712 - val_loss: 0.5315 - val_accuracy: 0.5370\n",
            "Epoch 147/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4464 - accuracy: 0.5702 - val_loss: 0.5314 - val_accuracy: 0.5370\n",
            "Epoch 148/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4460 - accuracy: 0.5712 - val_loss: 0.5316 - val_accuracy: 0.5365\n",
            "Epoch 149/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4457 - accuracy: 0.5717 - val_loss: 0.5314 - val_accuracy: 0.5367\n",
            "Epoch 150/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4451 - accuracy: 0.5725 - val_loss: 0.5334 - val_accuracy: 0.5396\n",
            "Epoch 151/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4455 - accuracy: 0.5722 - val_loss: 0.5326 - val_accuracy: 0.5387\n",
            "Epoch 152/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4452 - accuracy: 0.5729 - val_loss: 0.5327 - val_accuracy: 0.5385\n",
            "Epoch 153/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4451 - accuracy: 0.5726 - val_loss: 0.5322 - val_accuracy: 0.5374\n",
            "Epoch 154/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4449 - accuracy: 0.5733 - val_loss: 0.5319 - val_accuracy: 0.5381\n",
            "Epoch 155/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4445 - accuracy: 0.5737 - val_loss: 0.5323 - val_accuracy: 0.5391\n",
            "Epoch 156/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4441 - accuracy: 0.5734 - val_loss: 0.5324 - val_accuracy: 0.5383\n",
            "Epoch 157/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4440 - accuracy: 0.5740 - val_loss: 0.5341 - val_accuracy: 0.5381\n",
            "Epoch 158/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4440 - accuracy: 0.5740 - val_loss: 0.5323 - val_accuracy: 0.5378\n",
            "Epoch 159/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4434 - accuracy: 0.5739 - val_loss: 0.5331 - val_accuracy: 0.5376\n",
            "Epoch 160/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4435 - accuracy: 0.5743 - val_loss: 0.5334 - val_accuracy: 0.5389\n",
            "Epoch 161/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4430 - accuracy: 0.5745 - val_loss: 0.5336 - val_accuracy: 0.5407\n",
            "Epoch 162/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4429 - accuracy: 0.5748 - val_loss: 0.5331 - val_accuracy: 0.5391\n",
            "Epoch 163/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4427 - accuracy: 0.5743 - val_loss: 0.5334 - val_accuracy: 0.5396\n",
            "Epoch 164/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4427 - accuracy: 0.5748 - val_loss: 0.5334 - val_accuracy: 0.5396\n",
            "Epoch 165/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4430 - accuracy: 0.5745 - val_loss: 0.5340 - val_accuracy: 0.5391\n",
            "Epoch 166/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4422 - accuracy: 0.5753 - val_loss: 0.5332 - val_accuracy: 0.5404\n",
            "Epoch 167/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4420 - accuracy: 0.5747 - val_loss: 0.5345 - val_accuracy: 0.5391\n",
            "Epoch 168/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4418 - accuracy: 0.5754 - val_loss: 0.5349 - val_accuracy: 0.5391\n",
            "Epoch 169/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4413 - accuracy: 0.5760 - val_loss: 0.5341 - val_accuracy: 0.5393\n",
            "Epoch 170/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4410 - accuracy: 0.5758 - val_loss: 0.5349 - val_accuracy: 0.5406\n",
            "Epoch 171/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4413 - accuracy: 0.5756 - val_loss: 0.5344 - val_accuracy: 0.5389\n",
            "Epoch 172/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4408 - accuracy: 0.5767 - val_loss: 0.5343 - val_accuracy: 0.5393\n",
            "Epoch 173/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4406 - accuracy: 0.5768 - val_loss: 0.5378 - val_accuracy: 0.5398\n",
            "Epoch 174/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4404 - accuracy: 0.5770 - val_loss: 0.5354 - val_accuracy: 0.5383\n",
            "Epoch 175/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4400 - accuracy: 0.5769 - val_loss: 0.5354 - val_accuracy: 0.5398\n",
            "Epoch 176/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4398 - accuracy: 0.5775 - val_loss: 0.5345 - val_accuracy: 0.5385\n",
            "Epoch 177/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4396 - accuracy: 0.5770 - val_loss: 0.5348 - val_accuracy: 0.5398\n",
            "Epoch 178/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4396 - accuracy: 0.5775 - val_loss: 0.5358 - val_accuracy: 0.5389\n",
            "Epoch 179/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4395 - accuracy: 0.5772 - val_loss: 0.5358 - val_accuracy: 0.5398\n",
            "Epoch 180/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4396 - accuracy: 0.5779 - val_loss: 0.5351 - val_accuracy: 0.5400\n",
            "Epoch 181/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4389 - accuracy: 0.5775 - val_loss: 0.5357 - val_accuracy: 0.5385\n",
            "Epoch 182/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4388 - accuracy: 0.5779 - val_loss: 0.5354 - val_accuracy: 0.5393\n",
            "Epoch 183/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4381 - accuracy: 0.5788 - val_loss: 0.5367 - val_accuracy: 0.5389\n",
            "Epoch 184/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4380 - accuracy: 0.5787 - val_loss: 0.5375 - val_accuracy: 0.5391\n",
            "Epoch 185/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4381 - accuracy: 0.5784 - val_loss: 0.5359 - val_accuracy: 0.5396\n",
            "Epoch 186/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4379 - accuracy: 0.5787 - val_loss: 0.5374 - val_accuracy: 0.5394\n",
            "Epoch 187/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4378 - accuracy: 0.5794 - val_loss: 0.5361 - val_accuracy: 0.5391\n",
            "Epoch 188/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4370 - accuracy: 0.5801 - val_loss: 0.5376 - val_accuracy: 0.5404\n",
            "Epoch 189/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4366 - accuracy: 0.5798 - val_loss: 0.5359 - val_accuracy: 0.5393\n",
            "Epoch 190/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4367 - accuracy: 0.5800 - val_loss: 0.5368 - val_accuracy: 0.5402\n",
            "Epoch 191/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4367 - accuracy: 0.5802 - val_loss: 0.5356 - val_accuracy: 0.5389\n",
            "Epoch 192/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4360 - accuracy: 0.5798 - val_loss: 0.5377 - val_accuracy: 0.5402\n",
            "Epoch 193/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4357 - accuracy: 0.5805 - val_loss: 0.5379 - val_accuracy: 0.5404\n",
            "Epoch 194/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4356 - accuracy: 0.5806 - val_loss: 0.5368 - val_accuracy: 0.5415\n",
            "Epoch 195/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4353 - accuracy: 0.5809 - val_loss: 0.5369 - val_accuracy: 0.5411\n",
            "Epoch 196/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4350 - accuracy: 0.5818 - val_loss: 0.5372 - val_accuracy: 0.5406\n",
            "Epoch 197/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4350 - accuracy: 0.5813 - val_loss: 0.5366 - val_accuracy: 0.5417\n",
            "Epoch 198/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4348 - accuracy: 0.5816 - val_loss: 0.5371 - val_accuracy: 0.5407\n",
            "Epoch 199/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4344 - accuracy: 0.5819 - val_loss: 0.5379 - val_accuracy: 0.5409\n",
            "Epoch 200/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4362 - accuracy: 0.5808 - val_loss: 0.5384 - val_accuracy: 0.5409\n",
            "Epoch 201/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4351 - accuracy: 0.5815 - val_loss: 0.5381 - val_accuracy: 0.5411\n",
            "Epoch 202/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4347 - accuracy: 0.5823 - val_loss: 0.5369 - val_accuracy: 0.5411\n",
            "Epoch 203/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4339 - accuracy: 0.5827 - val_loss: 0.5376 - val_accuracy: 0.5409\n",
            "Epoch 204/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4334 - accuracy: 0.5825 - val_loss: 0.5376 - val_accuracy: 0.5413\n",
            "Epoch 205/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4335 - accuracy: 0.5830 - val_loss: 0.5377 - val_accuracy: 0.5406\n",
            "Epoch 206/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4332 - accuracy: 0.5826 - val_loss: 0.5378 - val_accuracy: 0.5420\n",
            "Epoch 207/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4327 - accuracy: 0.5833 - val_loss: 0.5385 - val_accuracy: 0.5413\n",
            "Epoch 208/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4326 - accuracy: 0.5837 - val_loss: 0.5380 - val_accuracy: 0.5415\n",
            "Epoch 209/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4327 - accuracy: 0.5840 - val_loss: 0.5387 - val_accuracy: 0.5420\n",
            "Epoch 210/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4323 - accuracy: 0.5840 - val_loss: 0.5389 - val_accuracy: 0.5417\n",
            "Epoch 211/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4322 - accuracy: 0.5844 - val_loss: 0.5384 - val_accuracy: 0.5419\n",
            "Epoch 212/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4321 - accuracy: 0.5839 - val_loss: 0.5386 - val_accuracy: 0.5409\n",
            "Epoch 213/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4320 - accuracy: 0.5850 - val_loss: 0.5390 - val_accuracy: 0.5415\n",
            "Epoch 214/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4315 - accuracy: 0.5852 - val_loss: 0.5396 - val_accuracy: 0.5419\n",
            "Epoch 215/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4313 - accuracy: 0.5854 - val_loss: 0.5379 - val_accuracy: 0.5413\n",
            "Epoch 216/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4312 - accuracy: 0.5851 - val_loss: 0.5398 - val_accuracy: 0.5420\n",
            "Epoch 217/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4309 - accuracy: 0.5857 - val_loss: 0.5388 - val_accuracy: 0.5413\n",
            "Epoch 218/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4307 - accuracy: 0.5860 - val_loss: 0.5396 - val_accuracy: 0.5404\n",
            "Epoch 219/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4308 - accuracy: 0.5863 - val_loss: 0.5395 - val_accuracy: 0.5415\n",
            "Epoch 220/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4305 - accuracy: 0.5863 - val_loss: 0.5395 - val_accuracy: 0.5415\n",
            "Epoch 221/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4303 - accuracy: 0.5866 - val_loss: 0.5405 - val_accuracy: 0.5407\n",
            "Epoch 222/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4301 - accuracy: 0.5860 - val_loss: 0.5397 - val_accuracy: 0.5417\n",
            "Epoch 223/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4296 - accuracy: 0.5871 - val_loss: 0.5412 - val_accuracy: 0.5422\n",
            "Epoch 224/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4295 - accuracy: 0.5877 - val_loss: 0.5412 - val_accuracy: 0.5411\n",
            "Epoch 225/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4299 - accuracy: 0.5874 - val_loss: 0.5408 - val_accuracy: 0.5415\n",
            "Epoch 226/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4295 - accuracy: 0.5871 - val_loss: 0.5402 - val_accuracy: 0.5424\n",
            "Epoch 227/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4295 - accuracy: 0.5877 - val_loss: 0.5406 - val_accuracy: 0.5409\n",
            "Epoch 228/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4291 - accuracy: 0.5879 - val_loss: 0.5420 - val_accuracy: 0.5422\n",
            "Epoch 229/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4291 - accuracy: 0.5879 - val_loss: 0.5414 - val_accuracy: 0.5413\n",
            "Epoch 230/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4288 - accuracy: 0.5885 - val_loss: 0.5406 - val_accuracy: 0.5422\n",
            "Epoch 231/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4288 - accuracy: 0.5877 - val_loss: 0.5409 - val_accuracy: 0.5417\n",
            "Epoch 232/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4290 - accuracy: 0.5877 - val_loss: 0.5412 - val_accuracy: 0.5409\n",
            "Epoch 233/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4282 - accuracy: 0.5887 - val_loss: 0.5406 - val_accuracy: 0.5413\n",
            "Epoch 234/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4280 - accuracy: 0.5887 - val_loss: 0.5410 - val_accuracy: 0.5420\n",
            "Epoch 235/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4284 - accuracy: 0.5890 - val_loss: 0.5419 - val_accuracy: 0.5417\n",
            "Epoch 236/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4281 - accuracy: 0.5891 - val_loss: 0.5419 - val_accuracy: 0.5420\n",
            "Epoch 237/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4275 - accuracy: 0.5894 - val_loss: 0.5419 - val_accuracy: 0.5424\n",
            "Epoch 238/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4274 - accuracy: 0.5895 - val_loss: 0.5419 - val_accuracy: 0.5424\n",
            "Epoch 239/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4273 - accuracy: 0.5897 - val_loss: 0.5429 - val_accuracy: 0.5420\n",
            "Epoch 240/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4276 - accuracy: 0.5894 - val_loss: 0.5419 - val_accuracy: 0.5422\n",
            "Epoch 241/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4267 - accuracy: 0.5893 - val_loss: 0.5422 - val_accuracy: 0.5426\n",
            "Epoch 242/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4270 - accuracy: 0.5902 - val_loss: 0.5411 - val_accuracy: 0.5424\n",
            "Epoch 243/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.5902 - val_loss: 0.5426 - val_accuracy: 0.5430\n",
            "Epoch 244/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.5904 - val_loss: 0.5413 - val_accuracy: 0.5422\n",
            "Epoch 245/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4268 - accuracy: 0.5898 - val_loss: 0.5433 - val_accuracy: 0.5426\n",
            "Epoch 246/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4266 - accuracy: 0.5905 - val_loss: 0.5423 - val_accuracy: 0.5424\n",
            "Epoch 247/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4265 - accuracy: 0.5907 - val_loss: 0.5416 - val_accuracy: 0.5426\n",
            "Epoch 248/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4262 - accuracy: 0.5910 - val_loss: 0.5403 - val_accuracy: 0.5415\n",
            "Epoch 249/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4263 - accuracy: 0.5903 - val_loss: 0.5413 - val_accuracy: 0.5424\n",
            "Epoch 250/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4257 - accuracy: 0.5913 - val_loss: 0.5417 - val_accuracy: 0.5426\n",
            "Epoch 251/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4256 - accuracy: 0.5913 - val_loss: 0.5419 - val_accuracy: 0.5428\n",
            "Epoch 252/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.5914 - val_loss: 0.5420 - val_accuracy: 0.5443\n",
            "Epoch 253/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4253 - accuracy: 0.5918 - val_loss: 0.5428 - val_accuracy: 0.5437\n",
            "Epoch 254/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4252 - accuracy: 0.5917 - val_loss: 0.5426 - val_accuracy: 0.5437\n",
            "Epoch 255/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4254 - accuracy: 0.5917 - val_loss: 0.5421 - val_accuracy: 0.5437\n",
            "Epoch 256/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4252 - accuracy: 0.5915 - val_loss: 0.5427 - val_accuracy: 0.5430\n",
            "Epoch 257/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4250 - accuracy: 0.5917 - val_loss: 0.5424 - val_accuracy: 0.5435\n",
            "Epoch 258/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4248 - accuracy: 0.5926 - val_loss: 0.5427 - val_accuracy: 0.5424\n",
            "Epoch 259/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4244 - accuracy: 0.5921 - val_loss: 0.5423 - val_accuracy: 0.5430\n",
            "Epoch 260/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4243 - accuracy: 0.5923 - val_loss: 0.5427 - val_accuracy: 0.5435\n",
            "Epoch 261/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4241 - accuracy: 0.5921 - val_loss: 0.5433 - val_accuracy: 0.5439\n",
            "Epoch 262/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4241 - accuracy: 0.5922 - val_loss: 0.5433 - val_accuracy: 0.5441\n",
            "Epoch 263/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4239 - accuracy: 0.5925 - val_loss: 0.5443 - val_accuracy: 0.5457\n",
            "Epoch 264/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4245 - accuracy: 0.5923 - val_loss: 0.5432 - val_accuracy: 0.5433\n",
            "Epoch 265/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4237 - accuracy: 0.5925 - val_loss: 0.5432 - val_accuracy: 0.5446\n",
            "Epoch 266/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4236 - accuracy: 0.5921 - val_loss: 0.5437 - val_accuracy: 0.5433\n",
            "Epoch 267/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.5927 - val_loss: 0.5441 - val_accuracy: 0.5437\n",
            "Epoch 268/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4231 - accuracy: 0.5932 - val_loss: 0.5445 - val_accuracy: 0.5448\n",
            "Epoch 269/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4235 - accuracy: 0.5932 - val_loss: 0.5464 - val_accuracy: 0.5435\n",
            "Epoch 270/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4233 - accuracy: 0.5930 - val_loss: 0.5437 - val_accuracy: 0.5446\n",
            "Epoch 271/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.5936 - val_loss: 0.5460 - val_accuracy: 0.5446\n",
            "Epoch 272/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4228 - accuracy: 0.5937 - val_loss: 0.5449 - val_accuracy: 0.5437\n",
            "Epoch 273/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4228 - accuracy: 0.5934 - val_loss: 0.5442 - val_accuracy: 0.5456\n",
            "Epoch 274/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4227 - accuracy: 0.5937 - val_loss: 0.5445 - val_accuracy: 0.5444\n",
            "Epoch 275/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4221 - accuracy: 0.5939 - val_loss: 0.5445 - val_accuracy: 0.5443\n",
            "Epoch 276/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4223 - accuracy: 0.5940 - val_loss: 0.5441 - val_accuracy: 0.5443\n",
            "Epoch 277/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4230 - accuracy: 0.5932 - val_loss: 0.5444 - val_accuracy: 0.5444\n",
            "Epoch 278/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.5944 - val_loss: 0.5445 - val_accuracy: 0.5443\n",
            "Epoch 279/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4220 - accuracy: 0.5944 - val_loss: 0.5443 - val_accuracy: 0.5463\n",
            "Epoch 280/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4219 - accuracy: 0.5946 - val_loss: 0.5446 - val_accuracy: 0.5452\n",
            "Epoch 281/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4215 - accuracy: 0.5948 - val_loss: 0.5446 - val_accuracy: 0.5450\n",
            "Epoch 282/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4216 - accuracy: 0.5951 - val_loss: 0.5460 - val_accuracy: 0.5461\n",
            "Epoch 283/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4213 - accuracy: 0.5952 - val_loss: 0.5440 - val_accuracy: 0.5448\n",
            "Epoch 284/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4210 - accuracy: 0.5948 - val_loss: 0.5451 - val_accuracy: 0.5457\n",
            "Epoch 285/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4209 - accuracy: 0.5950 - val_loss: 0.5451 - val_accuracy: 0.5456\n",
            "Epoch 286/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.5952 - val_loss: 0.5448 - val_accuracy: 0.5454\n",
            "Epoch 287/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4212 - accuracy: 0.5943 - val_loss: 0.5456 - val_accuracy: 0.5446\n",
            "Epoch 288/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4208 - accuracy: 0.5954 - val_loss: 0.5456 - val_accuracy: 0.5465\n",
            "Epoch 289/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4202 - accuracy: 0.5957 - val_loss: 0.5454 - val_accuracy: 0.5461\n",
            "Epoch 290/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4202 - accuracy: 0.5956 - val_loss: 0.5455 - val_accuracy: 0.5459\n",
            "Epoch 291/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4202 - accuracy: 0.5960 - val_loss: 0.5454 - val_accuracy: 0.5439\n",
            "Epoch 292/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4200 - accuracy: 0.5963 - val_loss: 0.5460 - val_accuracy: 0.5448\n",
            "Epoch 293/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4198 - accuracy: 0.5956 - val_loss: 0.5471 - val_accuracy: 0.5443\n",
            "Epoch 294/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4194 - accuracy: 0.5971 - val_loss: 0.5464 - val_accuracy: 0.5456\n",
            "Epoch 295/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4194 - accuracy: 0.5967 - val_loss: 0.5449 - val_accuracy: 0.5444\n",
            "Epoch 296/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4199 - accuracy: 0.5964 - val_loss: 0.5467 - val_accuracy: 0.5457\n",
            "Epoch 297/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4206 - accuracy: 0.5966 - val_loss: 0.5443 - val_accuracy: 0.5441\n",
            "Epoch 298/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4199 - accuracy: 0.5971 - val_loss: 0.5463 - val_accuracy: 0.5446\n",
            "Epoch 299/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4193 - accuracy: 0.5972 - val_loss: 0.5466 - val_accuracy: 0.5457\n",
            "Epoch 300/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4194 - accuracy: 0.5972 - val_loss: 0.5483 - val_accuracy: 0.5446\n",
            "Epoch 301/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4193 - accuracy: 0.5978 - val_loss: 0.5463 - val_accuracy: 0.5444\n",
            "Epoch 302/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4189 - accuracy: 0.5972 - val_loss: 0.5482 - val_accuracy: 0.5454\n",
            "Epoch 303/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4190 - accuracy: 0.5979 - val_loss: 0.5477 - val_accuracy: 0.5454\n",
            "Epoch 304/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4187 - accuracy: 0.5972 - val_loss: 0.5490 - val_accuracy: 0.5443\n",
            "Epoch 305/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4190 - accuracy: 0.5976 - val_loss: 0.5471 - val_accuracy: 0.5446\n",
            "Epoch 306/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4186 - accuracy: 0.5980 - val_loss: 0.5483 - val_accuracy: 0.5452\n",
            "Epoch 307/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4184 - accuracy: 0.5982 - val_loss: 0.5482 - val_accuracy: 0.5457\n",
            "Epoch 308/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4183 - accuracy: 0.5990 - val_loss: 0.5507 - val_accuracy: 0.5456\n",
            "Epoch 309/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.5985 - val_loss: 0.5477 - val_accuracy: 0.5454\n",
            "Epoch 310/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4182 - accuracy: 0.5988 - val_loss: 0.5491 - val_accuracy: 0.5461\n",
            "Epoch 311/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4179 - accuracy: 0.5985 - val_loss: 0.5491 - val_accuracy: 0.5457\n",
            "Epoch 312/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4177 - accuracy: 0.5988 - val_loss: 0.5489 - val_accuracy: 0.5452\n",
            "Epoch 313/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4177 - accuracy: 0.5990 - val_loss: 0.5491 - val_accuracy: 0.5454\n",
            "Epoch 314/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4178 - accuracy: 0.5993 - val_loss: 0.5494 - val_accuracy: 0.5454\n",
            "Epoch 315/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4177 - accuracy: 0.5989 - val_loss: 0.5493 - val_accuracy: 0.5450\n",
            "Epoch 316/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4176 - accuracy: 0.5994 - val_loss: 0.5490 - val_accuracy: 0.5450\n",
            "Epoch 317/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4173 - accuracy: 0.5996 - val_loss: 0.5499 - val_accuracy: 0.5454\n",
            "Epoch 318/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4181 - accuracy: 0.5991 - val_loss: 0.5482 - val_accuracy: 0.5456\n",
            "Epoch 319/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4179 - accuracy: 0.5994 - val_loss: 0.5483 - val_accuracy: 0.5452\n",
            "Epoch 320/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4182 - accuracy: 0.5994 - val_loss: 0.5478 - val_accuracy: 0.5469\n",
            "Epoch 321/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4173 - accuracy: 0.6000 - val_loss: 0.5486 - val_accuracy: 0.5454\n",
            "Epoch 322/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4170 - accuracy: 0.6000 - val_loss: 0.5485 - val_accuracy: 0.5459\n",
            "Epoch 323/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4167 - accuracy: 0.6005 - val_loss: 0.5491 - val_accuracy: 0.5457\n",
            "Epoch 324/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4165 - accuracy: 0.6006 - val_loss: 0.5487 - val_accuracy: 0.5448\n",
            "Epoch 325/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4165 - accuracy: 0.6006 - val_loss: 0.5499 - val_accuracy: 0.5461\n",
            "Epoch 326/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4166 - accuracy: 0.5998 - val_loss: 0.5499 - val_accuracy: 0.5457\n",
            "Epoch 327/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4162 - accuracy: 0.6011 - val_loss: 0.5486 - val_accuracy: 0.5452\n",
            "Epoch 328/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4159 - accuracy: 0.6010 - val_loss: 0.5486 - val_accuracy: 0.5452\n",
            "Epoch 329/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4160 - accuracy: 0.6006 - val_loss: 0.5495 - val_accuracy: 0.5457\n",
            "Epoch 330/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4172 - accuracy: 0.6003 - val_loss: 0.5507 - val_accuracy: 0.5450\n",
            "Epoch 331/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4161 - accuracy: 0.6013 - val_loss: 0.5501 - val_accuracy: 0.5457\n",
            "Epoch 332/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4158 - accuracy: 0.6011 - val_loss: 0.5498 - val_accuracy: 0.5452\n",
            "Epoch 333/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4156 - accuracy: 0.6013 - val_loss: 0.5494 - val_accuracy: 0.5444\n",
            "Epoch 334/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4155 - accuracy: 0.6016 - val_loss: 0.5494 - val_accuracy: 0.5443\n",
            "Epoch 335/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4155 - accuracy: 0.6020 - val_loss: 0.5499 - val_accuracy: 0.5459\n",
            "Epoch 336/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4154 - accuracy: 0.6021 - val_loss: 0.5506 - val_accuracy: 0.5454\n",
            "Epoch 337/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4151 - accuracy: 0.6025 - val_loss: 0.5511 - val_accuracy: 0.5461\n",
            "Epoch 338/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4151 - accuracy: 0.6022 - val_loss: 0.5500 - val_accuracy: 0.5459\n",
            "Epoch 339/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4150 - accuracy: 0.6022 - val_loss: 0.5511 - val_accuracy: 0.5467\n",
            "Epoch 340/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4148 - accuracy: 0.6027 - val_loss: 0.5499 - val_accuracy: 0.5457\n",
            "Epoch 341/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4148 - accuracy: 0.6029 - val_loss: 0.5487 - val_accuracy: 0.5446\n",
            "Epoch 342/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4149 - accuracy: 0.6026 - val_loss: 0.5497 - val_accuracy: 0.5459\n",
            "Epoch 343/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4146 - accuracy: 0.6024 - val_loss: 0.5493 - val_accuracy: 0.5454\n",
            "Epoch 344/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4147 - accuracy: 0.6025 - val_loss: 0.5497 - val_accuracy: 0.5461\n",
            "Epoch 345/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4146 - accuracy: 0.6025 - val_loss: 0.5484 - val_accuracy: 0.5465\n",
            "Epoch 346/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4144 - accuracy: 0.6027 - val_loss: 0.5501 - val_accuracy: 0.5454\n",
            "Epoch 347/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4145 - accuracy: 0.6033 - val_loss: 0.5490 - val_accuracy: 0.5461\n",
            "Epoch 348/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4143 - accuracy: 0.6033 - val_loss: 0.5487 - val_accuracy: 0.5459\n",
            "Epoch 349/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4149 - accuracy: 0.6030 - val_loss: 0.5505 - val_accuracy: 0.5456\n",
            "Epoch 350/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4148 - accuracy: 0.6036 - val_loss: 0.5504 - val_accuracy: 0.5459\n",
            "Epoch 351/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4144 - accuracy: 0.6033 - val_loss: 0.5500 - val_accuracy: 0.5465\n",
            "Epoch 352/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4142 - accuracy: 0.6033 - val_loss: 0.5491 - val_accuracy: 0.5476\n",
            "Epoch 353/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4139 - accuracy: 0.6034 - val_loss: 0.5502 - val_accuracy: 0.5472\n",
            "Epoch 354/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4137 - accuracy: 0.6038 - val_loss: 0.5500 - val_accuracy: 0.5465\n",
            "Epoch 355/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4138 - accuracy: 0.6034 - val_loss: 0.5510 - val_accuracy: 0.5465\n",
            "Epoch 356/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4136 - accuracy: 0.6040 - val_loss: 0.5497 - val_accuracy: 0.5474\n",
            "Epoch 357/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4136 - accuracy: 0.6034 - val_loss: 0.5501 - val_accuracy: 0.5459\n",
            "Epoch 358/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4136 - accuracy: 0.6044 - val_loss: 0.5496 - val_accuracy: 0.5452\n",
            "Epoch 359/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4141 - accuracy: 0.6036 - val_loss: 0.5493 - val_accuracy: 0.5472\n",
            "Epoch 360/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4140 - accuracy: 0.6030 - val_loss: 0.5529 - val_accuracy: 0.5467\n",
            "Epoch 361/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4138 - accuracy: 0.6041 - val_loss: 0.5505 - val_accuracy: 0.5463\n",
            "Epoch 362/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4132 - accuracy: 0.6040 - val_loss: 0.5505 - val_accuracy: 0.5467\n",
            "Epoch 363/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4130 - accuracy: 0.6042 - val_loss: 0.5495 - val_accuracy: 0.5469\n",
            "Epoch 364/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4130 - accuracy: 0.6043 - val_loss: 0.5498 - val_accuracy: 0.5467\n",
            "Epoch 365/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4129 - accuracy: 0.6040 - val_loss: 0.5513 - val_accuracy: 0.5469\n",
            "Epoch 366/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4127 - accuracy: 0.6040 - val_loss: 0.5511 - val_accuracy: 0.5463\n",
            "Epoch 367/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4126 - accuracy: 0.6046 - val_loss: 0.5505 - val_accuracy: 0.5470\n",
            "Epoch 368/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4127 - accuracy: 0.6045 - val_loss: 0.5497 - val_accuracy: 0.5472\n",
            "Epoch 369/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4127 - accuracy: 0.6046 - val_loss: 0.5504 - val_accuracy: 0.5470\n",
            "Epoch 370/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4127 - accuracy: 0.6042 - val_loss: 0.5504 - val_accuracy: 0.5465\n",
            "Epoch 371/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4124 - accuracy: 0.6042 - val_loss: 0.5510 - val_accuracy: 0.5465\n",
            "Epoch 372/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4126 - accuracy: 0.6048 - val_loss: 0.5501 - val_accuracy: 0.5472\n",
            "Epoch 373/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4124 - accuracy: 0.6045 - val_loss: 0.5515 - val_accuracy: 0.5465\n",
            "Epoch 374/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4129 - accuracy: 0.6038 - val_loss: 0.5520 - val_accuracy: 0.5465\n",
            "Epoch 375/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4130 - accuracy: 0.6048 - val_loss: 0.5495 - val_accuracy: 0.5470\n",
            "Epoch 376/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4121 - accuracy: 0.6045 - val_loss: 0.5531 - val_accuracy: 0.5463\n",
            "Epoch 377/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4122 - accuracy: 0.6050 - val_loss: 0.5505 - val_accuracy: 0.5461\n",
            "Epoch 378/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4118 - accuracy: 0.6049 - val_loss: 0.5524 - val_accuracy: 0.5461\n",
            "Epoch 379/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4119 - accuracy: 0.6054 - val_loss: 0.5518 - val_accuracy: 0.5463\n",
            "Epoch 380/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4119 - accuracy: 0.6051 - val_loss: 0.5518 - val_accuracy: 0.5469\n",
            "Epoch 381/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4115 - accuracy: 0.6052 - val_loss: 0.5496 - val_accuracy: 0.5465\n",
            "Epoch 382/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4116 - accuracy: 0.6052 - val_loss: 0.5522 - val_accuracy: 0.5463\n",
            "Epoch 383/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4117 - accuracy: 0.6050 - val_loss: 0.5513 - val_accuracy: 0.5469\n",
            "Epoch 384/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4118 - accuracy: 0.6050 - val_loss: 0.5501 - val_accuracy: 0.5476\n",
            "Epoch 385/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4116 - accuracy: 0.6054 - val_loss: 0.5519 - val_accuracy: 0.5465\n",
            "Epoch 386/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4118 - accuracy: 0.6056 - val_loss: 0.5529 - val_accuracy: 0.5465\n",
            "Epoch 387/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4117 - accuracy: 0.6055 - val_loss: 0.5510 - val_accuracy: 0.5469\n",
            "Epoch 388/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4115 - accuracy: 0.6054 - val_loss: 0.5522 - val_accuracy: 0.5467\n",
            "Epoch 389/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4113 - accuracy: 0.6056 - val_loss: 0.5530 - val_accuracy: 0.5467\n",
            "Epoch 390/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4113 - accuracy: 0.6053 - val_loss: 0.5512 - val_accuracy: 0.5467\n",
            "Epoch 391/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4112 - accuracy: 0.6057 - val_loss: 0.5514 - val_accuracy: 0.5463\n",
            "Epoch 392/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4111 - accuracy: 0.6057 - val_loss: 0.5527 - val_accuracy: 0.5467\n",
            "Epoch 393/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4109 - accuracy: 0.6056 - val_loss: 0.5520 - val_accuracy: 0.5469\n",
            "Epoch 394/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4108 - accuracy: 0.6060 - val_loss: 0.5519 - val_accuracy: 0.5467\n",
            "Epoch 395/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4110 - accuracy: 0.6060 - val_loss: 0.5509 - val_accuracy: 0.5470\n",
            "Epoch 396/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4106 - accuracy: 0.6058 - val_loss: 0.5514 - val_accuracy: 0.5463\n",
            "Epoch 397/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4107 - accuracy: 0.6062 - val_loss: 0.5508 - val_accuracy: 0.5463\n",
            "Epoch 398/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4106 - accuracy: 0.6063 - val_loss: 0.5521 - val_accuracy: 0.5463\n",
            "Epoch 399/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4107 - accuracy: 0.6063 - val_loss: 0.5524 - val_accuracy: 0.5456\n",
            "Epoch 400/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4104 - accuracy: 0.6065 - val_loss: 0.5515 - val_accuracy: 0.5467\n",
            "Epoch 401/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4104 - accuracy: 0.6064 - val_loss: 0.5513 - val_accuracy: 0.5472\n",
            "Epoch 402/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4101 - accuracy: 0.6063 - val_loss: 0.5503 - val_accuracy: 0.5470\n",
            "Epoch 403/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4101 - accuracy: 0.6064 - val_loss: 0.5509 - val_accuracy: 0.5457\n",
            "Epoch 404/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4101 - accuracy: 0.6064 - val_loss: 0.5502 - val_accuracy: 0.5459\n",
            "Epoch 405/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4103 - accuracy: 0.6060 - val_loss: 0.5509 - val_accuracy: 0.5457\n",
            "Epoch 406/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4097 - accuracy: 0.6069 - val_loss: 0.5519 - val_accuracy: 0.5461\n",
            "Epoch 407/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4099 - accuracy: 0.6069 - val_loss: 0.5505 - val_accuracy: 0.5463\n",
            "Epoch 408/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4096 - accuracy: 0.6071 - val_loss: 0.5507 - val_accuracy: 0.5465\n",
            "Epoch 409/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4094 - accuracy: 0.6067 - val_loss: 0.5523 - val_accuracy: 0.5456\n",
            "Epoch 410/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4095 - accuracy: 0.6072 - val_loss: 0.5528 - val_accuracy: 0.5452\n",
            "Epoch 411/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4102 - accuracy: 0.6074 - val_loss: 0.5510 - val_accuracy: 0.5441\n",
            "Epoch 412/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4095 - accuracy: 0.6075 - val_loss: 0.5524 - val_accuracy: 0.5450\n",
            "Epoch 413/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4092 - accuracy: 0.6074 - val_loss: 0.5519 - val_accuracy: 0.5457\n",
            "Epoch 414/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4090 - accuracy: 0.6073 - val_loss: 0.5513 - val_accuracy: 0.5448\n",
            "Epoch 415/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4093 - accuracy: 0.6075 - val_loss: 0.5536 - val_accuracy: 0.5444\n",
            "Epoch 416/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4088 - accuracy: 0.6076 - val_loss: 0.5503 - val_accuracy: 0.5461\n",
            "Epoch 417/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4090 - accuracy: 0.6075 - val_loss: 0.5537 - val_accuracy: 0.5448\n",
            "Epoch 418/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4089 - accuracy: 0.6078 - val_loss: 0.5524 - val_accuracy: 0.5450\n",
            "Epoch 419/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4087 - accuracy: 0.6073 - val_loss: 0.5519 - val_accuracy: 0.5452\n",
            "Epoch 420/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4086 - accuracy: 0.6079 - val_loss: 0.5536 - val_accuracy: 0.5443\n",
            "Epoch 421/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4088 - accuracy: 0.6078 - val_loss: 0.5515 - val_accuracy: 0.5467\n",
            "Epoch 422/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4085 - accuracy: 0.6083 - val_loss: 0.5520 - val_accuracy: 0.5452\n",
            "Epoch 423/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4083 - accuracy: 0.6081 - val_loss: 0.5531 - val_accuracy: 0.5439\n",
            "Epoch 424/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4083 - accuracy: 0.6085 - val_loss: 0.5532 - val_accuracy: 0.5448\n",
            "Epoch 425/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4081 - accuracy: 0.6081 - val_loss: 0.5525 - val_accuracy: 0.5454\n",
            "Epoch 426/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4083 - accuracy: 0.6081 - val_loss: 0.5536 - val_accuracy: 0.5446\n",
            "Epoch 427/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4080 - accuracy: 0.6077 - val_loss: 0.5539 - val_accuracy: 0.5444\n",
            "Epoch 428/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4081 - accuracy: 0.6070 - val_loss: 0.5530 - val_accuracy: 0.5448\n",
            "Epoch 429/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4079 - accuracy: 0.6086 - val_loss: 0.5522 - val_accuracy: 0.5450\n",
            "Epoch 430/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4079 - accuracy: 0.6083 - val_loss: 0.5526 - val_accuracy: 0.5446\n",
            "Epoch 431/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4079 - accuracy: 0.6087 - val_loss: 0.5543 - val_accuracy: 0.5446\n",
            "Epoch 432/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4078 - accuracy: 0.6063 - val_loss: 0.5541 - val_accuracy: 0.5444\n",
            "Epoch 433/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4083 - accuracy: 0.6083 - val_loss: 0.5532 - val_accuracy: 0.5444\n",
            "Epoch 434/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4077 - accuracy: 0.6086 - val_loss: 0.5527 - val_accuracy: 0.5443\n",
            "Epoch 435/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4074 - accuracy: 0.6087 - val_loss: 0.5537 - val_accuracy: 0.5444\n",
            "Epoch 436/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4076 - accuracy: 0.6080 - val_loss: 0.5533 - val_accuracy: 0.5450\n",
            "Epoch 437/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4075 - accuracy: 0.6088 - val_loss: 0.5535 - val_accuracy: 0.5452\n",
            "Epoch 438/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4072 - accuracy: 0.6085 - val_loss: 0.5536 - val_accuracy: 0.5437\n",
            "Epoch 439/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4075 - accuracy: 0.6092 - val_loss: 0.5528 - val_accuracy: 0.5437\n",
            "Epoch 440/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4074 - accuracy: 0.6085 - val_loss: 0.5535 - val_accuracy: 0.5439\n",
            "Epoch 441/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4076 - accuracy: 0.6085 - val_loss: 0.5529 - val_accuracy: 0.5444\n",
            "Epoch 442/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4076 - accuracy: 0.6094 - val_loss: 0.5533 - val_accuracy: 0.5443\n",
            "Epoch 443/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4072 - accuracy: 0.6086 - val_loss: 0.5546 - val_accuracy: 0.5446\n",
            "Epoch 444/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4072 - accuracy: 0.6094 - val_loss: 0.5535 - val_accuracy: 0.5446\n",
            "Epoch 445/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4069 - accuracy: 0.6094 - val_loss: 0.5559 - val_accuracy: 0.5443\n",
            "Epoch 446/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4070 - accuracy: 0.6095 - val_loss: 0.5532 - val_accuracy: 0.5444\n",
            "Epoch 447/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4068 - accuracy: 0.6094 - val_loss: 0.5544 - val_accuracy: 0.5446\n",
            "Epoch 448/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4069 - accuracy: 0.6098 - val_loss: 0.5537 - val_accuracy: 0.5448\n",
            "Epoch 449/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4068 - accuracy: 0.6094 - val_loss: 0.5562 - val_accuracy: 0.5441\n",
            "Epoch 450/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4066 - accuracy: 0.6092 - val_loss: 0.5549 - val_accuracy: 0.5428\n",
            "Epoch 451/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4066 - accuracy: 0.6089 - val_loss: 0.5545 - val_accuracy: 0.5439\n",
            "Epoch 452/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4066 - accuracy: 0.6096 - val_loss: 0.5549 - val_accuracy: 0.5444\n",
            "Epoch 453/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4063 - accuracy: 0.6085 - val_loss: 0.5563 - val_accuracy: 0.5444\n",
            "Epoch 454/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4063 - accuracy: 0.6095 - val_loss: 0.5570 - val_accuracy: 0.5443\n",
            "Epoch 455/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4061 - accuracy: 0.6095 - val_loss: 0.5575 - val_accuracy: 0.5444\n",
            "Epoch 456/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4062 - accuracy: 0.6096 - val_loss: 0.5574 - val_accuracy: 0.5413\n",
            "Epoch 457/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4060 - accuracy: 0.6081 - val_loss: 0.5568 - val_accuracy: 0.5452\n",
            "Epoch 458/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4058 - accuracy: 0.6098 - val_loss: 0.5603 - val_accuracy: 0.5446\n",
            "Epoch 459/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4061 - accuracy: 0.6102 - val_loss: 0.5575 - val_accuracy: 0.5448\n",
            "Epoch 460/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4061 - accuracy: 0.6089 - val_loss: 0.5584 - val_accuracy: 0.5450\n",
            "Epoch 461/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4059 - accuracy: 0.6097 - val_loss: 0.5587 - val_accuracy: 0.5456\n",
            "Epoch 462/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4055 - accuracy: 0.6102 - val_loss: 0.5571 - val_accuracy: 0.5444\n",
            "Epoch 463/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4058 - accuracy: 0.6095 - val_loss: 0.5573 - val_accuracy: 0.5446\n",
            "Epoch 464/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4055 - accuracy: 0.6107 - val_loss: 0.5572 - val_accuracy: 0.5461\n",
            "Epoch 465/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4055 - accuracy: 0.6096 - val_loss: 0.5569 - val_accuracy: 0.5459\n",
            "Epoch 466/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4054 - accuracy: 0.6102 - val_loss: 0.5559 - val_accuracy: 0.5450\n",
            "Epoch 467/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4051 - accuracy: 0.6101 - val_loss: 0.5561 - val_accuracy: 0.5444\n",
            "Epoch 468/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4051 - accuracy: 0.6106 - val_loss: 0.5579 - val_accuracy: 0.5443\n",
            "Epoch 469/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4052 - accuracy: 0.6109 - val_loss: 0.5574 - val_accuracy: 0.5450\n",
            "Epoch 470/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4051 - accuracy: 0.6110 - val_loss: 0.5592 - val_accuracy: 0.5452\n",
            "Epoch 471/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4055 - accuracy: 0.6070 - val_loss: 0.5575 - val_accuracy: 0.5452\n",
            "Epoch 472/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4049 - accuracy: 0.6102 - val_loss: 0.5561 - val_accuracy: 0.5452\n",
            "Epoch 473/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4051 - accuracy: 0.6106 - val_loss: 0.5566 - val_accuracy: 0.5450\n",
            "Epoch 474/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4051 - accuracy: 0.6087 - val_loss: 0.5568 - val_accuracy: 0.5435\n",
            "Epoch 475/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4051 - accuracy: 0.6106 - val_loss: 0.5572 - val_accuracy: 0.5450\n",
            "Epoch 476/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4052 - accuracy: 0.6089 - val_loss: 0.5579 - val_accuracy: 0.5446\n",
            "Epoch 477/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4052 - accuracy: 0.6106 - val_loss: 0.5581 - val_accuracy: 0.5446\n",
            "Epoch 478/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4047 - accuracy: 0.6097 - val_loss: 0.5575 - val_accuracy: 0.5443\n",
            "Epoch 479/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4049 - accuracy: 0.6115 - val_loss: 0.5592 - val_accuracy: 0.5443\n",
            "Epoch 480/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4049 - accuracy: 0.6092 - val_loss: 0.5569 - val_accuracy: 0.5443\n",
            "Epoch 481/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4048 - accuracy: 0.6108 - val_loss: 0.5580 - val_accuracy: 0.5443\n",
            "Epoch 482/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4049 - accuracy: 0.6115 - val_loss: 0.5590 - val_accuracy: 0.5433\n",
            "Epoch 483/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4047 - accuracy: 0.6112 - val_loss: 0.5592 - val_accuracy: 0.5443\n",
            "Epoch 484/500\n",
            "99/99 [==============================] - 1s 10ms/step - loss: 0.4051 - accuracy: 0.6114 - val_loss: 0.5586 - val_accuracy: 0.5450\n",
            "Epoch 485/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4046 - accuracy: 0.6111 - val_loss: 0.5591 - val_accuracy: 0.5444\n",
            "Epoch 486/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4044 - accuracy: 0.6114 - val_loss: 0.5586 - val_accuracy: 0.5443\n",
            "Epoch 487/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4041 - accuracy: 0.6114 - val_loss: 0.5598 - val_accuracy: 0.5441\n",
            "Epoch 488/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4042 - accuracy: 0.6117 - val_loss: 0.5592 - val_accuracy: 0.5439\n",
            "Epoch 489/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4041 - accuracy: 0.6117 - val_loss: 0.5607 - val_accuracy: 0.5441\n",
            "Epoch 490/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4040 - accuracy: 0.6119 - val_loss: 0.5596 - val_accuracy: 0.5452\n",
            "Epoch 491/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4040 - accuracy: 0.6110 - val_loss: 0.5592 - val_accuracy: 0.5444\n",
            "Epoch 492/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4041 - accuracy: 0.6117 - val_loss: 0.5591 - val_accuracy: 0.5385\n",
            "Epoch 493/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4039 - accuracy: 0.6105 - val_loss: 0.5604 - val_accuracy: 0.5437\n",
            "Epoch 494/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4038 - accuracy: 0.6121 - val_loss: 0.5601 - val_accuracy: 0.5428\n",
            "Epoch 495/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4040 - accuracy: 0.6110 - val_loss: 0.5603 - val_accuracy: 0.5431\n",
            "Epoch 496/500\n",
            "99/99 [==============================] - 1s 8ms/step - loss: 0.4038 - accuracy: 0.6124 - val_loss: 0.5593 - val_accuracy: 0.5433\n",
            "Epoch 497/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4038 - accuracy: 0.6108 - val_loss: 0.5595 - val_accuracy: 0.5433\n",
            "Epoch 498/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4037 - accuracy: 0.6122 - val_loss: 0.5595 - val_accuracy: 0.5435\n",
            "Epoch 499/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4038 - accuracy: 0.6111 - val_loss: 0.5596 - val_accuracy: 0.5437\n",
            "Epoch 500/500\n",
            "99/99 [==============================] - 1s 7ms/step - loss: 0.4035 - accuracy: 0.6121 - val_loss: 0.5597 - val_accuracy: 0.5391\n",
            "Training time finished.\n",
            "500 epochs in       369.82 sec\n",
            "0.5390(max: 0.5475)\n",
            "Size dataframe: 18000 records\n",
            "Size training: 12600 records\n",
            "Size validation: 5400 records\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "What would you like to do?\n",
            " 0 - Leave\n",
            " 1 - Data Structure\n",
            " 2 - Train\n",
            " 3 - Predict\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 163, in <module>\n",
            "  File \"main.py\", line 12, in main\n",
            "    stage = ui.choose_stage()\n",
            "  File \"/content/gdrive/My Drive/BSI/TCC/Códigos/TCC-rede-siamesa-google-colab/cli_input.py\", line 18, in choose_stage\n",
            "    option_chosen = input(\"What would you like to do?\\n 0 - Leave\\n 1 - Data Structure\\n 2 - Train\\n 3 - Predict\\n\")\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SjrY5Z610jl"
      },
      "source": [
        "**Show graph result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dix9OI6v__q6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}